from fastapi import APIRouter, Depends, HTTPException, UploadFile, File, Form
from fastapi.responses import JSONResponse
from sqlalchemy.orm import Session
from sqlalchemy.exc import SQLAlchemyError
from typing import Dict, List, Any, Optional, Tuple
import logging
import pandas as pd
import numpy as np
import io
import os
import json
from datetime import datetime
from enum import Enum
from difflib import SequenceMatcher
import re

from app.api.deps import get_db, get_current_active_user
from app.models.models import User, Country, Category, Port, Company, Supplier, Product, Ship
from app.core.config import settings

router = APIRouter()
logger = logging.getLogger(__name__)

def clean_nan_values(obj):
    """é€’å½’æ¸…ç†å¯¹è±¡ä¸­çš„NaNå€¼ï¼Œå°†å…¶è½¬æ¢ä¸ºNone"""
    if isinstance(obj, dict):
        return {k: clean_nan_values(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [clean_nan_values(item) for item in obj]
    elif isinstance(obj, float) and (np.isnan(obj) or np.isinf(obj)):
        return None
    elif pd.isna(obj):
        return None
    else:
        return obj

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
ALLOWED_EXTENSIONS = {'.xlsx', '.xls', '.csv'}
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MB

class DuplicateHandlingStrategy(Enum):
    """é‡å¤æ•°æ®å¤„ç†ç­–ç•¥"""
    SKIP = "skip"           # è·³è¿‡é‡å¤æ•°æ®
    ERROR = "error"         # æŠ¥é”™åœæ­¢
    UPDATE = "update"       # æ›´æ–°ç°æœ‰æ•°æ®

class ImportResult:
    """å¯¼å…¥ç»“æœç±»"""
    def __init__(self):
        self.success_count = 0
        self.error_count = 0
        self.skipped_count = 0
        self.errors = []
        self.skipped_items = []
        self.warnings = []

    def to_dict(self) -> Dict[str, Any]:
        # æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯
        formatted_errors = format_validation_errors(self.errors) if self.errors else []

        result = {
            "success_count": self.success_count,
            "error_count": self.error_count,
            "skipped_count": self.skipped_count,
            "errors": self.errors,  # ä¿ç•™åŸå§‹é”™è¯¯ç”¨äºå…¼å®¹æ€§
            "formatted_errors": formatted_errors,  # æ–°å¢æ ¼å¼åŒ–é”™è¯¯
            "skipped_items": self.skipped_items,
            "warnings": self.warnings
        }

        # æ¸…ç†NaNå€¼ä»¥é¿å…JSONåºåˆ—åŒ–é”™è¯¯
        return clean_nan_values(result)

class PreCheckResult:
    """æ•°æ®é¢„æ£€æŸ¥ç»“æœç±»"""
    def __init__(self):
        self.new_items = []          # æ•°æ®åº“ä¸­ä¸å­˜åœ¨çš„æ–°æ•°æ®
        self.similar_items = []      # æ•°æ®åº“ä¸­å­˜åœ¨ç›¸ä¼¼çš„æ•°æ®
        self.exact_duplicates = []   # å®Œå…¨é‡å¤çš„æ•°æ®
        self.validation_errors = []  # éªŒè¯é”™è¯¯

    def to_dict(self) -> Dict[str, Any]:
        # æ ¼å¼åŒ–éªŒè¯é”™è¯¯
        formatted_errors = []
        raw_errors = []

        for error_item in self.validation_errors:
            if isinstance(error_item, dict) and 'errors' in error_item:
                # å¤„ç†åŒ…å«é”™è¯¯åˆ—è¡¨çš„é¡¹ç›®
                for error in error_item['errors']:
                    raw_errors.append(error)
                    formatted_errors.append(format_user_friendly_error(error))
            elif isinstance(error_item, str):
                # å¤„ç†ç›´æ¥çš„é”™è¯¯å­—ç¬¦ä¸²
                raw_errors.append(error_item)
                formatted_errors.append(format_user_friendly_error(error_item))
            else:
                # ä¿æŒåŸæœ‰æ ¼å¼
                raw_errors.append(str(error_item))
                formatted_errors.append(format_user_friendly_error(str(error_item)))

        result = {
            "new_items": self.new_items,
            "similar_items": self.similar_items,
            "exact_duplicates": self.exact_duplicates,
            "validation_errors": self.validation_errors,  # ä¿ç•™åŸå§‹æ ¼å¼ç”¨äºå…¼å®¹æ€§
            "formatted_errors": formatted_errors,  # æ–°å¢æ ¼å¼åŒ–é”™è¯¯
            "raw_errors": raw_errors,  # åŸå§‹é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•
            "summary": {
                "new_count": len(self.new_items),
                "similar_count": len(self.similar_items),
                "duplicate_count": len(self.exact_duplicates),
                "error_count": len(self.validation_errors)
            }
        }

        # æ¸…ç†NaNå€¼ä»¥é¿å…JSONåºåˆ—åŒ–é”™è¯¯
        return clean_nan_values(result)

# æŒ‰æ•°æ®ç±»å‹å®šä¹‰é‡å¤æ•°æ®å¤„ç†ç­–ç•¥
DUPLICATE_STRATEGIES = {
    "countries": DuplicateHandlingStrategy.SKIP,    # åŸºç¡€æ•°æ®è·³è¿‡é‡å¤
    "categories": DuplicateHandlingStrategy.SKIP,   # åŸºç¡€æ•°æ®è·³è¿‡é‡å¤
    "ports": DuplicateHandlingStrategy.ERROR,       # åœ°ç†æ•°æ®æŠ¥é”™
    "companies": DuplicateHandlingStrategy.ERROR,   # å…¬å¸æ•°æ®æŠ¥é”™
    "suppliers": DuplicateHandlingStrategy.ERROR,   # ä¾›åº”å•†æ•°æ®æŠ¥é”™
    "ships": DuplicateHandlingStrategy.ERROR,       # èˆ¹èˆ¶æ•°æ®æŠ¥é”™
    "products": DuplicateHandlingStrategy.ERROR,    # äº§å“æ•°æ®æŠ¥é”™
}

def validate_file_type(filename: str) -> bool:
    """éªŒè¯æ–‡ä»¶ç±»å‹"""
    return any(filename.lower().endswith(ext) for ext in ALLOWED_EXTENSIONS)

def build_foreign_key_cache(table_name: str, db: Session) -> Dict[str, Dict[str, Any]]:
    """æ„å»ºå¤–é”®æ•°æ®ç¼“å­˜ï¼Œé¿å…é‡å¤æ•°æ®åº“æŸ¥è¯¢"""
    cache = {}

    try:
        # æ ¹æ®è¡¨ç±»å‹åŠ è½½ç›¸åº”çš„å¤–é”®æ•°æ®
        if table_name == "products":
            # äº§å“è¡¨éœ€è¦çš„æ‰€æœ‰å¤–é”®æ•°æ®
            cache['countries'] = {c.name: {"id": c.id, "name": c.name, "code": c.code}
                                for c in db.query(Country).all()}
            cache['categories'] = {c.name: {"id": c.id, "name": c.name}
                                 for c in db.query(Category).all()}
            cache['suppliers'] = {s.name: {"id": s.id, "name": s.name, "country": s.country.name if s.country else None}
                                for s in db.query(Supplier).all()}
            cache['ports'] = {p.name: {"id": p.id, "name": p.name, "code": p.code, "country": p.country.name if p.country else None}
                            for p in db.query(Port).all()}
        elif table_name == "ports":
            cache['countries'] = {c.name: {"id": c.id, "name": c.name, "code": c.code}
                                for c in db.query(Country).all()}
        elif table_name == "companies":
            cache['countries'] = {c.name: {"id": c.id, "name": c.name, "code": c.code}
                                for c in db.query(Country).all()}
        elif table_name == "suppliers":
            cache['countries'] = {c.name: {"id": c.id, "name": c.name, "code": c.code}
                                for c in db.query(Country).all()}
        elif table_name == "ships":
            cache['companies'] = {c.name: {"id": c.id, "name": c.name, "country": c.country.name if c.country else None}
                                for c in db.query(Company).all()}

        logger.info(f"å¤–é”®ç¼“å­˜æ„å»ºå®Œæˆ: {table_name}, ç¼“å­˜è¡¨æ•°é‡: {len(cache)}")

    except Exception as e:
        logger.error(f"æ„å»ºå¤–é”®ç¼“å­˜å¤±è´¥: {str(e)}")

    return cache

def build_existing_data_cache(table_name: str, db: Session) -> List[Dict[str, Any]]:
    """æ„å»ºç°æœ‰æ•°æ®ç¼“å­˜ï¼Œç”¨äºé‡å¤æ£€æŸ¥å’Œç›¸ä¼¼æ€§æ£€æŸ¥"""
    cache = []

    try:
        if table_name == "countries":
            cache = [{"id": c.id, "name": c.name, "code": c.code} for c in db.query(Country).all()]
        elif table_name == "categories":
            cache = [{"id": c.id, "name": c.name} for c in db.query(Category).all()]
        elif table_name == "ports":
            cache = [{"id": p.id, "name": p.name, "code": p.code, "country": p.country.name if p.country else None}
                   for p in db.query(Port).all()]
        elif table_name == "companies":
            cache = [{"id": c.id, "name": c.name, "country": c.country.name if c.country else None}
                   for c in db.query(Company).all()]
        elif table_name == "suppliers":
            cache = [{"id": s.id, "name": s.name, "country": s.country.name if s.country else None}
                   for s in db.query(Supplier).all()]
        elif table_name == "ships":
            cache = [{"id": s.id, "name": s.name, "company": s.company.name if s.company else None}
                   for s in db.query(Ship).all()]
        elif table_name == "products":
            cache = [{"id": p.id, "product_name_en": p.product_name_en, "product_name_jp": p.product_name_jp, "code": p.code}
                   for p in db.query(Product).all()]

        logger.info(f"ç°æœ‰æ•°æ®ç¼“å­˜æ„å»ºå®Œæˆ: {table_name}, è®°å½•æ•°é‡: {len(cache)}")

    except Exception as e:
        logger.error(f"æ„å»ºç°æœ‰æ•°æ®ç¼“å­˜å¤±è´¥: {str(e)}")

    return cache

def calculate_similarity(str1: str, str2: str) -> float:
    """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ (0-1)"""
    if not str1 or not str2:
        return 0.0

    # æ ‡å‡†åŒ–å­—ç¬¦ä¸²ï¼šå»é™¤ç©ºæ ¼ã€è½¬å°å†™
    s1 = str(str1).strip().lower()
    s2 = str(str2).strip().lower()

    if s1 == s2:
        return 1.0

    # ä½¿ç”¨SequenceMatcherè®¡ç®—ç›¸ä¼¼åº¦
    return SequenceMatcher(None, s1, s2).ratio()

def find_similar_items(table_name: str, new_item: Dict[str, Any], db: Session, threshold: float = 0.8) -> List[Dict[str, Any]]:
    """æŸ¥æ‰¾æ•°æ®åº“ä¸­ä¸æ–°é¡¹ç›®ç›¸ä¼¼çš„é¡¹ç›®"""
    similar_items = []

    try:
        if table_name == "countries":
            existing_items = db.query(Country).all()
            for item in existing_items:
                similarity = calculate_similarity(new_item.get("name", ""), item.name)
                if similarity >= threshold:
                    similar_items.append({
                        "existing_item": {"id": item.id, "name": item.name, "code": item.code},
                        "similarity": similarity,
                        "match_field": "name"
                    })

        elif table_name == "categories":
            existing_items = db.query(Category).all()
            for item in existing_items:
                similarity = calculate_similarity(new_item.get("name", ""), item.name)
                if similarity >= threshold:
                    similar_items.append({
                        "existing_item": {"id": item.id, "name": item.name},
                        "similarity": similarity,
                        "match_field": "name"
                    })

        elif table_name == "ports":
            existing_items = db.query(Port).all()
            for item in existing_items:
                name_similarity = calculate_similarity(new_item.get("name", ""), item.name)
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": item.id,
                            "name": item.name,
                            "code": item.code,
                            "country": item.country.name if item.country else None
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "companies":
            existing_items = db.query(Company).all()
            for item in existing_items:
                name_similarity = calculate_similarity(new_item.get("name", ""), item.name)
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": item.id,
                            "name": item.name,
                            "country": item.country.name if item.country else None
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "suppliers":
            existing_items = db.query(Supplier).all()
            for item in existing_items:
                name_similarity = calculate_similarity(new_item.get("name", ""), item.name)
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": item.id,
                            "name": item.name,
                            "country": item.country.name if item.country else None
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "products":
            existing_items = db.query(Product).all()
            for item in existing_items:
                name_similarity = calculate_similarity(new_item.get("product_name_en", ""), item.product_name_en)
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": item.id,
                            "product_name_en": item.product_name_en,
                            "product_name_jp": item.product_name_jp,
                            "code": item.code,
                            "country": item.country.name if item.country else None
                        },
                        "similarity": name_similarity,
                        "match_field": "product_name_en"
                    })

        elif table_name == "ships":
            existing_items = db.query(Ship).all()
            for item in existing_items:
                name_similarity = calculate_similarity(new_item.get("name", ""), item.name)
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": item.id,
                            "name": item.name,
                            "company": item.company.name if item.company else None
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

    except Exception as e:
        logger.error(f"æŸ¥æ‰¾ç›¸ä¼¼é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")

    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
    similar_items.sort(key=lambda x: x["similarity"], reverse=True)
    return similar_items

def precheck_data(table_name: str, df: pd.DataFrame, db: Session) -> PreCheckResult:
    """ç®€åŒ–ç‰ˆé¢„æ£€æŸ¥ - åªåšåŸºæœ¬éªŒè¯"""
    result = PreCheckResult()

    try:
        # è·å–éªŒè¯è§„åˆ™
        rules = get_table_validation_rules(table_name)
        if not rules:
            result.validation_errors.append(f"ä¸æ”¯æŒçš„è¡¨ç±»å‹: {table_name}")
            return result

        logger.info(f"å¼€å§‹ç®€åŒ–é¢„æ£€æŸ¥ {table_name} æ•°æ®ï¼Œå…± {len(df)} è¡Œ")

        # ğŸ”¥ ç®€åŒ–é€»è¾‘ï¼šæ£€æŸ¥æ•°æ®åº“ä¸­æ˜¯å¦æœ‰ç°æœ‰æ•°æ®
        existing_count = 0
        if table_name == "products":
            existing_count = db.query(Product).count()
        elif table_name == "countries":
            existing_count = db.query(Country).count()
        elif table_name == "categories":
            existing_count = db.query(Category).count()
        elif table_name == "suppliers":
            existing_count = db.query(Supplier).count()
        elif table_name == "ports":
            existing_count = db.query(Port).count()
        elif table_name == "companies":
            existing_count = db.query(Company).count()
        elif table_name == "ships":
            existing_count = db.query(Ship).count()

        logger.info(f"æ•°æ®åº“ä¸­ç°æœ‰ {table_name} æ•°æ®: {existing_count} æ¡")

        # ğŸ”¥ ç®€åŒ–é€»è¾‘ï¼šå¦‚æœæ•°æ®åº“ä¸ºç©ºï¼Œè·³è¿‡å¤æ‚æ£€æŸ¥
        if existing_count == 0:
            logger.info(f"{table_name} è¡¨ä¸ºç©ºï¼Œä½¿ç”¨å¿«é€ŸéªŒè¯æ¨¡å¼")
            return quick_precheck_for_empty_db(table_name, df, db, rules)

        # å¦‚æœæ•°æ®åº“æœ‰æ•°æ®ï¼ŒåªåšåŸºæœ¬éªŒè¯ï¼ˆä¸åšç›¸ä¼¼æ€§æ£€æŸ¥ï¼‰
        logger.info(f"{table_name} è¡¨æœ‰æ•°æ®ï¼Œä½¿ç”¨åŸºæœ¬éªŒè¯æ¨¡å¼")
        return basic_precheck_with_existing_data(table_name, df, db, rules)

    except Exception as e:
        logger.error(f"æ•°æ®é¢„æ£€æŸ¥å¤±è´¥: {str(e)}")
        result.validation_errors.append(f"é¢„æ£€æŸ¥è¿‡ç¨‹å‡ºé”™: {str(e)}")

    return result

def quick_precheck_for_empty_db(table_name: str, df: pd.DataFrame, db: Session, rules: Dict) -> PreCheckResult:
    """ç©ºæ•°æ®åº“çš„å¿«é€Ÿé¢„æ£€æŸ¥ - åªéªŒè¯æ ¼å¼å’Œå¤–é”®"""
    result = PreCheckResult()

    # é¢„åŠ è½½å¤–é”®æ•°æ®ï¼ˆåªåœ¨éœ€è¦æ—¶ï¼‰
    foreign_key_cache = {}
    foreign_keys = rules.get("foreign_keys", {})

    if foreign_keys:
        if "countries.name" in foreign_keys.values():
            foreign_key_cache['countries'] = {c.name: c.id for c in db.query(Country).all()}
        if "categories.name" in foreign_keys.values():
            foreign_key_cache['categories'] = {c.name: c.id for c in db.query(Category).all()}
        if "suppliers.name" in foreign_keys.values():
            foreign_key_cache['suppliers'] = {s.name: s.id for s in db.query(Supplier).all()}
        if "ports.name" in foreign_keys.values():
            foreign_key_cache['ports'] = {p.name: p.id for p in db.query(Port).all()}
        if "companies.name" in foreign_keys.values():
            foreign_key_cache['companies'] = {c.name: c.id for c in db.query(Company).all()}

    # å¿«é€ŸéªŒè¯æ¯è¡Œ
    for index, row in df.iterrows():
        row_number = index + 2
        row_dict = row.to_dict()

        # åªåšåŸºæœ¬éªŒè¯
        row_errors = validate_basic_fields_only(table_name, row, row_number, foreign_key_cache, rules)

        if row_errors:
            result.validation_errors.append({
                "row": row_number,
                "data": row_dict,
                "errors": row_errors
            })
        else:
            # æ•°æ®åº“ä¸ºç©ºï¼Œæ‰€æœ‰æœ‰æ•ˆæ•°æ®éƒ½æ˜¯æ–°æ•°æ®
            result.new_items.append({
                "row": row_number,
                "data": row_dict
            })

    return result

def basic_precheck_with_existing_data(table_name: str, df: pd.DataFrame, db: Session, rules: Dict) -> PreCheckResult:
    """æœ‰ç°æœ‰æ•°æ®æ—¶çš„åŸºæœ¬é¢„æ£€æŸ¥ - ä¸åšç›¸ä¼¼æ€§æ£€æŸ¥"""
    result = PreCheckResult()

    # é¢„åŠ è½½å¤–é”®æ•°æ®
    foreign_key_cache = {}
    foreign_keys = rules.get("foreign_keys", {})

    if foreign_keys:
        if "countries.name" in foreign_keys.values():
            foreign_key_cache['countries'] = {c.name: c.id for c in db.query(Country).all()}
        if "categories.name" in foreign_keys.values():
            foreign_key_cache['categories'] = {c.name: c.id for c in db.query(Category).all()}
        if "suppliers.name" in foreign_keys.values():
            foreign_key_cache['suppliers'] = {s.name: s.id for s in db.query(Supplier).all()}
        if "ports.name" in foreign_keys.values():
            foreign_key_cache['ports'] = {p.name: p.id for p in db.query(Port).all()}
        if "companies.name" in foreign_keys.values():
            foreign_key_cache['companies'] = {c.name: c.id for c in db.query(Company).all()}

    # åŸºæœ¬éªŒè¯æ¯è¡Œ
    for index, row in df.iterrows():
        row_number = index + 2
        row_dict = row.to_dict()

        # åŸºæœ¬éªŒè¯
        row_errors = validate_basic_fields_only(table_name, row, row_number, foreign_key_cache, rules)

        if row_errors:
            result.validation_errors.append({
                "row": row_number,
                "data": row_dict,
                "errors": row_errors
            })
        else:
            # ç®€å•çš„é‡å¤æ£€æŸ¥ï¼ˆåªæ£€æŸ¥ä¸»é”®å­—æ®µï¼‰
            is_duplicate = check_simple_duplicate(table_name, row_dict, db)
            if is_duplicate:
                result.exact_duplicates.append({
                    "row": row_number,
                    "data": row_dict,
                    "existing_item": is_duplicate
                })
            else:
                # æ ‡è®°ä¸ºæ–°æ•°æ®ï¼ˆè·³è¿‡ç›¸ä¼¼æ€§æ£€æŸ¥ï¼‰
                result.new_items.append({
                    "row": row_number,
                    "data": row_dict
                })

    return result

def validate_basic_fields_only(table_name: str, row: pd.Series, row_number: int, foreign_key_cache: Dict, rules: Dict) -> List[str]:
    """åªéªŒè¯åŸºæœ¬å­—æ®µ - ç®€åŒ–ç‰ˆæœ¬"""
    errors = []

    try:
        # éªŒè¯å¿…å¡«å­—æ®µ
        required_columns = rules.get("required_columns", [])
        for col in required_columns:
            if pd.isna(row.get(col)) or str(row.get(col, "")).strip() == "":
                errors.append(f"ç¬¬{row_number}è¡Œ: {col} ä¸èƒ½ä¸ºç©º")

        # ç®€åŒ–çš„å¤–é”®éªŒè¯
        foreign_keys = rules.get("foreign_keys", {})
        for fk_col, fk_ref in foreign_keys.items():
            if row.get(fk_col) and not pd.isna(row[fk_col]):
                value = str(row[fk_col]).strip()

                # ä½¿ç”¨ç¼“å­˜å¿«é€ŸéªŒè¯
                if fk_ref == "countries.name" and value not in foreign_key_cache.get('countries', {}):
                    available = list(foreign_key_cache.get('countries', {}).keys())[:3]
                    errors.append(f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{value}' ä¸å­˜åœ¨ã€‚å¯ç”¨: {available}")
                elif fk_ref == "categories.name" and value not in foreign_key_cache.get('categories', {}):
                    available = list(foreign_key_cache.get('categories', {}).keys())[:3]
                    errors.append(f"ç¬¬{row_number}è¡Œ: ç±»åˆ« '{value}' ä¸å­˜åœ¨ã€‚å¯ç”¨: {available}")
                elif fk_ref == "suppliers.name" and value not in foreign_key_cache.get('suppliers', {}):
                    errors.append(f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{value}' ä¸å­˜åœ¨")
                elif fk_ref == "ports.name" and value not in foreign_key_cache.get('ports', {}):
                    errors.append(f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{value}' ä¸å­˜åœ¨")
                elif fk_ref == "companies.name" and value not in foreign_key_cache.get('companies', {}):
                    errors.append(f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{value}' ä¸å­˜åœ¨")

        # åŸºæœ¬æ ¼å¼éªŒè¯ï¼ˆåªå¯¹äº§å“ï¼‰
        if table_name == "products":
            # éªŒè¯ä»·æ ¼
            if row.get("price") and not pd.isna(row["price"]):
                try:
                    price = float(row["price"])
                    if price < 0:
                        errors.append(f"ç¬¬{row_number}è¡Œ: ä»·æ ¼ä¸èƒ½ä¸ºè´Ÿæ•°")
                except (ValueError, TypeError):
                    errors.append(f"ç¬¬{row_number}è¡Œ: ä»·æ ¼æ ¼å¼é”™è¯¯")

            # pack_size å…è®¸å­—ç¬¦ä¸²ï¼Œä¸åšæ ¼å¼éªŒè¯

    except Exception as e:
        logger.error(f"éªŒè¯ç¬¬{row_number}è¡Œæ•°æ®æ—¶å‡ºé”™: {str(e)}")
        errors.append(f"ç¬¬{row_number}è¡Œ: éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")

    return errors

def check_simple_duplicate(table_name: str, new_item: Dict[str, Any], db: Session) -> Optional[Dict[str, Any]]:
    """ç®€å•çš„é‡å¤æ£€æŸ¥ - åªæ£€æŸ¥ä¸»è¦å­—æ®µ"""
    try:
        if table_name == "countries":
            existing = db.query(Country).filter(
                (Country.name == new_item.get("name")) |
                (Country.code == new_item.get("code"))
            ).first()
            if existing:
                return {"id": existing.id, "name": existing.name, "code": existing.code}

        elif table_name == "categories":
            existing = db.query(Category).filter(Category.name == new_item.get("name")).first()
            if existing:
                return {"id": existing.id, "name": existing.name}

        elif table_name == "products":
            existing = db.query(Product).filter(
                Product.product_name_en == new_item.get("product_name_en")
            ).first()
            if existing:
                return {
                    "id": existing.id,
                    "product_name_en": existing.product_name_en,
                    "code": existing.code
                }

        elif table_name == "suppliers":
            existing = db.query(Supplier).filter(Supplier.name == new_item.get("name")).first()
            if existing:
                return {"id": existing.id, "name": existing.name}

        elif table_name == "ports":
            existing = db.query(Port).filter(Port.name == new_item.get("name")).first()
            if existing:
                return {"id": existing.id, "name": existing.name}

        elif table_name == "companies":
            existing = db.query(Company).filter(Company.name == new_item.get("name")).first()
            if existing:
                return {"id": existing.id, "name": existing.name}

        elif table_name == "ships":
            existing = db.query(Ship).filter(Ship.name == new_item.get("name")).first()
            if existing:
                return {"id": existing.id, "name": existing.name}

    except Exception as e:
        logger.error(f"æ£€æŸ¥é‡å¤æ•°æ®æ—¶å‡ºé”™: {str(e)}")

    return None

def check_exact_duplicate(table_name: str, new_item: Dict[str, Any], db: Session) -> Optional[Dict[str, Any]]:
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å®Œå…¨é‡å¤çš„æ•°æ®"""
    try:
        if table_name == "countries":
            existing = db.query(Country).filter(
                (Country.name == new_item.get("name")) |
                (Country.code == new_item.get("code"))
            ).first()
            if existing:
                return {"id": existing.id, "name": existing.name, "code": existing.code}

        elif table_name == "categories":
            existing = db.query(Category).filter(Category.name == new_item.get("name")).first()
            if existing:
                return {"id": existing.id, "name": existing.name}

        elif table_name == "ports":
            existing = db.query(Port).filter(Port.name == new_item.get("name")).first()
            if existing:
                return {
                    "id": existing.id,
                    "name": existing.name,
                    "code": existing.code,
                    "country": existing.country.name if existing.country else None
                }

        elif table_name == "companies":
            existing = db.query(Company).filter(Company.name == new_item.get("name")).first()
            if existing:
                return {
                    "id": existing.id,
                    "name": existing.name,
                    "country": existing.country.name if existing.country else None
                }

        elif table_name == "suppliers":
            existing = db.query(Supplier).filter(Supplier.name == new_item.get("name")).first()
            if existing:
                return {
                    "id": existing.id,
                    "name": existing.name,
                    "country": existing.country.name if existing.country else None
                }

        elif table_name == "products":
            existing = db.query(Product).filter(Product.product_name_en == new_item.get("product_name_en")).first()
            if existing:
                return {
                    "id": existing.id,
                    "product_name_en": existing.product_name_en,
                    "product_name_jp": existing.product_name_jp,
                    "code": existing.code
                }

        elif table_name == "ships":
            existing = db.query(Ship).filter(Ship.name == new_item.get("name")).first()
            if existing:
                return {
                    "id": existing.id,
                    "name": existing.name,
                    "company": existing.company.name if existing.company else None
                }

    except Exception as e:
        logger.error(f"æ£€æŸ¥é‡å¤æ•°æ®æ—¶å‡ºé”™: {str(e)}")

    return None

def check_exact_duplicate_cached(table_name: str, new_item: Dict[str, Any], existing_data_cache: List[Dict]) -> Optional[Dict[str, Any]]:
    """æ£€æŸ¥æ˜¯å¦å­˜åœ¨å®Œå…¨é‡å¤çš„æ•°æ® - ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
    try:
        if table_name == "countries":
            for existing in existing_data_cache:
                if (existing.get("name") == new_item.get("name") or
                    existing.get("code") == new_item.get("code")):
                    return {"id": existing["id"], "name": existing["name"], "code": existing["code"]}

        elif table_name == "categories":
            for existing in existing_data_cache:
                if existing.get("name") == new_item.get("name"):
                    return {"id": existing["id"], "name": existing["name"]}

        elif table_name == "ports":
            for existing in existing_data_cache:
                if existing.get("name") == new_item.get("name"):
                    return {
                        "id": existing["id"],
                        "name": existing["name"],
                        "code": existing.get("code"),
                        "country": existing.get("country")
                    }

        elif table_name == "companies":
            for existing in existing_data_cache:
                if existing.get("name") == new_item.get("name"):
                    return {
                        "id": existing["id"],
                        "name": existing["name"],
                        "country": existing.get("country")
                    }

        elif table_name == "suppliers":
            for existing in existing_data_cache:
                if existing.get("name") == new_item.get("name"):
                    return {
                        "id": existing["id"],
                        "name": existing["name"],
                        "country": existing.get("country")
                    }

        elif table_name == "products":
            for existing in existing_data_cache:
                if existing.get("product_name_en") == new_item.get("product_name_en"):
                    return {
                        "id": existing["id"],
                        "product_name_en": existing["product_name_en"],
                        "product_name_jp": existing.get("product_name_jp"),
                        "code": existing.get("code")
                    }

        elif table_name == "ships":
            for existing in existing_data_cache:
                if existing.get("name") == new_item.get("name"):
                    return {
                        "id": existing["id"],
                        "name": existing["name"],
                        "company": existing.get("company")
                    }

    except Exception as e:
        logger.error(f"æ£€æŸ¥é‡å¤æ•°æ®æ—¶å‡ºé”™: {str(e)}")

    return None

def find_similar_items_cached(table_name: str, new_item: Dict[str, Any], existing_data_cache: List[Dict], threshold: float = 0.8) -> List[Dict[str, Any]]:
    """æŸ¥æ‰¾æ•°æ®åº“ä¸­ä¸æ–°é¡¹ç›®ç›¸ä¼¼çš„é¡¹ç›® - ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
    similar_items = []

    try:
        if table_name == "countries":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("name", ""), existing.get("name", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "name": existing["name"],
                            "code": existing.get("code")
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "categories":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("name", ""), existing.get("name", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "name": existing["name"]
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "products":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("product_name_en", ""), existing.get("product_name_en", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "product_name_en": existing["product_name_en"],
                            "product_name_jp": existing.get("product_name_jp"),
                            "code": existing.get("code")
                        },
                        "similarity": name_similarity,
                        "match_field": "product_name_en"
                    })

        elif table_name == "suppliers":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("name", ""), existing.get("name", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "name": existing["name"],
                            "country": existing.get("country")
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "ports":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("name", ""), existing.get("name", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "name": existing["name"],
                            "code": existing.get("code"),
                            "country": existing.get("country")
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "companies":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("name", ""), existing.get("name", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "name": existing["name"],
                            "country": existing.get("country")
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

        elif table_name == "ships":
            for existing in existing_data_cache:
                name_similarity = calculate_similarity(new_item.get("name", ""), existing.get("name", ""))
                if name_similarity >= threshold:
                    similar_items.append({
                        "existing_item": {
                            "id": existing["id"],
                            "name": existing["name"],
                            "company": existing.get("company")
                        },
                        "similarity": name_similarity,
                        "match_field": "name"
                    })

    except Exception as e:
        logger.error(f"æŸ¥æ‰¾ç›¸ä¼¼é¡¹ç›®æ—¶å‡ºé”™: {str(e)}")

    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
    similar_items.sort(key=lambda x: x["similarity"], reverse=True)
    return similar_items

def validate_all_data_before_import(table_name: str, df: pd.DataFrame, db: Session) -> Tuple[bool, ImportResult]:
    """
    åœ¨å¯¼å…¥å‰éªŒè¯æ‰€æœ‰æ•°æ®
    è¿”å›: (æ˜¯å¦é€šè¿‡éªŒè¯, éªŒè¯ç»“æœ)
    """
    result = ImportResult()

    try:
        # è·å–éªŒè¯è§„åˆ™
        rules = get_table_validation_rules(table_name)
        if not rules:
            result.errors.append(f"ä¸æ”¯æŒçš„è¡¨ç±»å‹: {table_name}")
            return False, result

        # éªŒè¯å¿…å¡«åˆ—
        required_columns = rules.get("required_columns", [])
        for col in required_columns:
            if col not in df.columns:
                result.errors.append(f"ç¼ºå°‘å¿…å¡«åˆ—: {col}")
                return False, result

        # é€è¡ŒéªŒè¯æ•°æ®
        for index, row in df.iterrows():
            row_errors = validate_single_row(table_name, row, index + 2, db, rules)
            result.errors.extend(row_errors)
            if row_errors:
                result.error_count += 1
            else:
                result.success_count += 1

        # å¦‚æœæœ‰é”™è¯¯ï¼ŒéªŒè¯å¤±è´¥
        if result.errors:
            return False, result

        return True, result

    except Exception as e:
        logger.error(f"æ•°æ®éªŒè¯å¤±è´¥: {e}")
        result.errors.append(f"æ•°æ®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False, result

def validate_single_row_cached(table_name: str, row: pd.Series, row_number: int, foreign_key_cache: Dict, rules: Dict) -> List[str]:
    """éªŒè¯å•è¡Œæ•°æ® - ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ç‰ˆæœ¬"""
    errors = []

    try:
        # éªŒè¯å¿…å¡«å­—æ®µ
        required_columns = rules.get("required_columns", [])
        for col in required_columns:
            if pd.isna(row.get(col)) or str(row.get(col, "")).strip() == "":
                errors.append(f"ç¬¬{row_number}è¡Œ: {col} ä¸èƒ½ä¸ºç©º")

        # éªŒè¯å¤–é”®å…³ç³»ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰
        foreign_keys = rules.get("foreign_keys", {})
        for fk_col, fk_ref in foreign_keys.items():
            if row.get(fk_col) and not pd.isna(row[fk_col]):
                value = str(row[fk_col]).strip()

                # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨ç¼“å­˜éªŒè¯å¤–é”®ï¼Œé¿å…æ•°æ®åº“æŸ¥è¯¢
                if not validate_foreign_key_cached(fk_col, value, fk_ref, foreign_key_cache):
                    # ç”Ÿæˆå‹å¥½çš„é”™è¯¯ä¿¡æ¯
                    debug_info = get_debug_info_from_cache(fk_ref, foreign_key_cache)
                    errors.append(f"ç¬¬{row_number}è¡Œ: {fk_col} '{value}' ä¸å­˜åœ¨ã€‚{debug_info}")

        # éªŒè¯æ•°æ®æ ¼å¼
        if table_name == "products":
            # éªŒè¯äº§å“ç‰¹æœ‰çš„å­—æ®µ
            errors.extend(validate_product_specific_fields(row, row_number))

    except Exception as e:
        logger.error(f"éªŒè¯ç¬¬{row_number}è¡Œæ•°æ®æ—¶å‡ºé”™: {str(e)}")
        errors.append(f"ç¬¬{row_number}è¡Œ: æ•°æ®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")

    return errors

def validate_foreign_key_cached(column: str, value: str, reference: str, cache: Dict) -> bool:
    """ä½¿ç”¨ç¼“å­˜éªŒè¯å¤–é”®å…³ç³»"""
    try:
        if reference == "countries.name":
            return value in cache.get('countries', {})
        elif reference == "categories.name":
            return value in cache.get('categories', {})
        elif reference == "companies.name":
            return value in cache.get('companies', {})
        elif reference == "suppliers.name":
            return value in cache.get('suppliers', {})
        elif reference == "ports.name":
            return value in cache.get('ports', {})

        return False
    except Exception:
        return False

def get_debug_info_from_cache(reference: str, cache: Dict) -> str:
    """ä»ç¼“å­˜è·å–è°ƒè¯•ä¿¡æ¯"""
    try:
        if reference == "countries.name":
            available = list(cache.get('countries', {}).keys())[:5]  # åªæ˜¾ç¤ºå‰5ä¸ª
            return f"å¯ç”¨å›½å®¶: {available}" + ("..." if len(cache.get('countries', {})) > 5 else "")
        elif reference == "categories.name":
            available = list(cache.get('categories', {}).keys())[:5]
            return f"å¯ç”¨ç±»åˆ«: {available}" + ("..." if len(cache.get('categories', {})) > 5 else "")
        elif reference == "companies.name":
            available = list(cache.get('companies', {}).keys())[:5]
            return f"å¯ç”¨å…¬å¸: {available}" + ("..." if len(cache.get('companies', {})) > 5 else "")
        elif reference == "suppliers.name":
            available = list(cache.get('suppliers', {}).keys())[:5]
            return f"å¯ç”¨ä¾›åº”å•†: {available}" + ("..." if len(cache.get('suppliers', {})) > 5 else "")
        elif reference == "ports.name":
            available = list(cache.get('ports', {}).keys())[:5]
            return f"å¯ç”¨æ¸¯å£: {available}" + ("..." if len(cache.get('ports', {})) > 5 else "")
        return ""
    except Exception as e:
        return f"è·å–è°ƒè¯•ä¿¡æ¯å¤±è´¥: {str(e)}"

def validate_single_row(table_name: str, row: pd.Series, row_number: int, db: Session, rules: Dict) -> List[str]:
    """éªŒè¯å•è¡Œæ•°æ®"""
    errors = []

    try:
        # éªŒè¯å¿…å¡«å­—æ®µ
        required_columns = rules.get("required_columns", [])
        for col in required_columns:
            if pd.isna(row.get(col)) or str(row.get(col, "")).strip() == "":
                errors.append(f"ç¬¬{row_number}è¡Œ: {col} ä¸èƒ½ä¸ºç©º")

        # éªŒè¯å¤–é”®å…³ç³»
        foreign_keys = rules.get("foreign_keys", {})
        for fk_col, fk_ref in foreign_keys.items():
            if row.get(fk_col) and not pd.isna(row[fk_col]):
                # å»é™¤ç©ºæ ¼å¹¶è·å–è°ƒè¯•ä¿¡æ¯
                value = str(row[fk_col]).strip()
                if not validate_foreign_key(fk_col, value, fk_ref, db):
                    # è·å–è°ƒè¯•ä¿¡æ¯
                    debug_info = get_debug_info_for_foreign_key_error(fk_ref, db)
                    errors.append(f"ç¬¬{row_number}è¡Œ: {fk_col} '{value}' ä¸å­˜åœ¨ã€‚{debug_info}")

        # éªŒè¯æ•°æ®æ ¼å¼
        if table_name == "products":
            # éªŒè¯äº§å“ç‰¹æœ‰çš„å­—æ®µ
            errors.extend(validate_product_specific_fields(row, row_number))

    except Exception as e:
        errors.append(f"ç¬¬{row_number}è¡Œ: éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ - {str(e)}")

    return errors

def format_user_friendly_error(error: str, row_number: int = None) -> dict:
    """å°†æŠ€æœ¯é”™è¯¯è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯"""

    # è§£æè¡Œå·
    if row_number is None and "ç¬¬" in error and "è¡Œ:" in error:
        try:
            row_part = error.split(":")[0]
            row_number = int(row_part.replace("ç¬¬", "").replace("è¡Œ", ""))
        except:
            row_number = 0

    # é”™è¯¯æ¨¡å¼åŒ¹é…
    if "ä¸å­˜åœ¨" in error:
        if "country_name" in error or "å›½å®¶" in error:
            return {
                "message": f"ç¬¬{row_number}è¡Œï¼šå›½å®¶åç§°åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨",
                "suggestion": "è¯·æ£€æŸ¥å›½å®¶åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥å›½å®¶æ•°æ®",
                "severity": "error",
                "type": "foreign_key_missing",
                "field": "country_name"
            }
        elif "category_name" in error or "ç±»åˆ«" in error:
            return {
                "message": f"ç¬¬{row_number}è¡Œï¼šäº§å“ç±»åˆ«åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨",
                "suggestion": "è¯·æ£€æŸ¥ç±»åˆ«åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥äº§å“ç±»åˆ«æ•°æ®",
                "severity": "error",
                "type": "foreign_key_missing",
                "field": "category_name"
            }
        elif "supplier_name" in error or "ä¾›åº”å•†" in error:
            return {
                "message": f"ç¬¬{row_number}è¡Œï¼šä¾›åº”å•†åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨",
                "suggestion": "è¯·æ£€æŸ¥ä¾›åº”å•†åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥ä¾›åº”å•†æ•°æ®",
                "severity": "error",
                "type": "foreign_key_missing",
                "field": "supplier_name"
            }
        elif "company_name" in error or "å…¬å¸" in error:
            return {
                "message": f"ç¬¬{row_number}è¡Œï¼šå…¬å¸åç§°åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨",
                "suggestion": "è¯·æ£€æŸ¥å…¬å¸åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥å…¬å¸æ•°æ®",
                "severity": "error",
                "type": "foreign_key_missing",
                "field": "company_name"
            }
        elif "port_name" in error or "æ¸¯å£" in error:
            return {
                "message": f"ç¬¬{row_number}è¡Œï¼šæ¸¯å£åç§°åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨",
                "suggestion": "è¯·æ£€æŸ¥æ¸¯å£åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥æ¸¯å£æ•°æ®",
                "severity": "error",
                "type": "foreign_key_missing",
                "field": "port_name"
            }
        else:
            return {
                "message": f"ç¬¬{row_number}è¡Œï¼šå¼•ç”¨çš„æ•°æ®åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨",
                "suggestion": "è¯·æ£€æŸ¥æ•°æ®æ‹¼å†™æˆ–å…ˆå¯¼å…¥ç›¸å…³çš„åŸºç¡€æ•°æ®",
                "severity": "error",
                "type": "foreign_key_missing"
            }

    elif "ä¸èƒ½ä¸ºç©º" in error:
        field_name = ""
        if "name" in error:
            field_name = "åç§°"
        elif "code" in error:
            field_name = "ä»£ç "
        elif "effective_from" in error:
            field_name = "èµ·å§‹æ—¥æœŸ"

        return {
            "message": f"ç¬¬{row_number}è¡Œï¼š{field_name}æ˜¯å¿…å¡«é¡¹ï¼Œä¸èƒ½ä¸ºç©º",
            "suggestion": "è¯·åœ¨Excelæ–‡ä»¶ä¸­å¡«å†™æ­¤å­—æ®µåé‡æ–°ä¸Šä¼ ",
            "severity": "error",
            "type": "required_field_missing",
            "field": field_name
        }

    elif "æ ¼å¼é”™è¯¯" in error or "æ ¼å¼ä¸æ­£ç¡®" in error:
        return {
            "message": f"ç¬¬{row_number}è¡Œï¼šæ•°æ®æ ¼å¼ä¸æ­£ç¡®",
            "suggestion": "è¯·å‚è€ƒä¸‹è½½çš„æ¨¡æ¿æ–‡ä»¶ä¸­çš„æ ¼å¼ç¤ºä¾‹",
            "severity": "warning",
            "type": "format_error"
        }

    elif "ä¸èƒ½ä¸ºè´Ÿæ•°" in error:
        return {
            "message": f"ç¬¬{row_number}è¡Œï¼šæ•°å€¼ä¸èƒ½ä¸ºè´Ÿæ•°",
            "suggestion": "è¯·è¾“å…¥å¤§äºç­‰äº0çš„æ•°å€¼",
            "severity": "error",
            "type": "invalid_value"
        }

    # é»˜è®¤æƒ…å†µï¼šä¿æŒåŸå§‹é”™è¯¯ä¿¡æ¯ä½†æ·»åŠ å»ºè®®
    return {
        "message": error,
        "suggestion": "è¯·æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå†…å®¹ï¼Œæˆ–å‚è€ƒæ¨¡æ¿æ–‡ä»¶",
        "severity": "error",
        "type": "general_error"
    }

def get_debug_info_for_foreign_key_error(reference: str, db: Session) -> str:
    """è·å–å¤–é”®é”™è¯¯çš„è°ƒè¯•ä¿¡æ¯"""
    try:
        if reference == "countries.name":
            all_items = db.query(Country.name).all()
            available = [item[0] for item in all_items]
            return f"å¯ç”¨å›½å®¶: {available}"
        elif reference == "categories.name":
            all_items = db.query(Category.name).all()
            available = [item[0] for item in all_items]
            return f"å¯ç”¨ç±»åˆ«: {available}"
        elif reference == "companies.name":
            all_items = db.query(Company.name).all()
            available = [item[0] for item in all_items]
            return f"å¯ç”¨å…¬å¸: {available}"
        elif reference == "suppliers.name":
            all_items = db.query(Supplier.name).all()
            available = [item[0] for item in all_items]
            return f"å¯ç”¨ä¾›åº”å•†: {available}"
        elif reference == "ports.name":
            all_items = db.query(Port.name).all()
            available = [item[0] for item in all_items]
            return f"å¯ç”¨æ¸¯å£: {available}"
        return ""
    except Exception as e:
        return f"è·å–è°ƒè¯•ä¿¡æ¯å¤±è´¥: {str(e)}"

def validate_foreign_key(column: str, value: str, reference: str, db: Session) -> bool:
    """éªŒè¯å¤–é”®å…³ç³»"""
    try:
        table_name, field_name = reference.split(".")

        if reference == "countries.name":
            return db.query(Country).filter(Country.name == value).first() is not None
        elif reference == "categories.name":
            return db.query(Category).filter(Category.name == value).first() is not None
        elif reference == "companies.name":
            return db.query(Company).filter(Company.name == value).first() is not None
        elif reference == "suppliers.name":
            return db.query(Supplier).filter(Supplier.name == value).first() is not None
        elif reference == "ports.name":
            return db.query(Port).filter(Port.name == value).first() is not None

        return False
    except Exception:
        return False

def validate_product_specific_fields(row: pd.Series, row_number: int) -> List[str]:
    """éªŒè¯äº§å“ç‰¹æœ‰å­—æ®µ"""
    errors = []

    # éªŒè¯ä»·æ ¼å­—æ®µ
    if row.get("price") and not pd.isna(row["price"]):
        try:
            price = float(row["price"])
            if price < 0:
                errors.append(f"ç¬¬{row_number}è¡Œ: price (ä»·æ ¼) ä¸èƒ½ä¸ºè´Ÿæ•°")
        except (ValueError, TypeError):
            errors.append(f"ç¬¬{row_number}è¡Œ: price (ä»·æ ¼) æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä¸ºæ•°å­—")

    # pack_size å…è®¸å­—ç¬¦ä¸²æ ¼å¼ï¼Œä¸åšæ•°å­—éªŒè¯
    # ä¾‹å¦‚: "30ä¸ª", "1ç®±", "500gè£…" ç­‰éƒ½æ˜¯æœ‰æ•ˆçš„

    return errors

def format_validation_errors(errors: List[str]) -> List[dict]:
    """æ ¼å¼åŒ–éªŒè¯é”™è¯¯ä¸ºç”¨æˆ·å‹å¥½çš„ä¿¡æ¯"""
    formatted_errors = []
    for error in errors:
        formatted_error = format_user_friendly_error(error)
        formatted_errors.append(formatted_error)

    return formatted_errors

def read_excel_file(file_content: bytes, filename: str) -> pd.DataFrame:
    """è¯»å–Excelæ–‡ä»¶"""
    try:
        if filename.lower().endswith('.csv'):
            # å°è¯•ä¸åŒçš„ç¼–ç 
            for encoding in ['utf-8', 'gbk', 'gb2312']:
                try:
                    df = pd.read_csv(io.BytesIO(file_content), encoding=encoding)
                    return df
                except UnicodeDecodeError:
                    continue
            raise ValueError("æ— æ³•è§£æCSVæ–‡ä»¶ç¼–ç ")
        else:
            df = pd.read_excel(io.BytesIO(file_content))
            return df
    except Exception as e:
        raise ValueError(f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

def validate_table_data(table_name: str, df: pd.DataFrame, db: Session) -> Dict[str, Any]:
    """éªŒè¯è¡¨æ•°æ®"""
    validation_result = {
        "total_rows": len(df),
        "valid_rows": 0,
        "invalid_rows": 0,
        "errors": [],
        "warnings": [],
        "data_preview": []
    }
    
    # è·å–è¡¨çš„éªŒè¯è§„åˆ™
    validation_rules = get_table_validation_rules(table_name)
    
    if not validation_rules:
        raise ValueError(f"ä¸æ”¯æŒçš„è¡¨ç±»å‹: {table_name}")
    
    # æ£€æŸ¥å¿…å¡«åˆ—
    required_columns = validation_rules.get("required_columns", [])
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        validation_result["errors"].append(f"ç¼ºå°‘å¿…å¡«åˆ—: {', '.join(missing_columns)}")
        return validation_result
    
    # é€è¡ŒéªŒè¯æ•°æ®
    for index, row in df.iterrows():
        row_errors = []
        
        # éªŒè¯å¿…å¡«å­—æ®µ
        for col in required_columns:
            if pd.isna(row[col]) or str(row[col]).strip() == '':
                row_errors.append(f"ç¬¬{index+2}è¡Œ: {col} ä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯å¤–é”®å…³ç³»
        if table_name == "ports" and "country_name" in row:
            if not pd.isna(row["country_name"]):
                country_name = str(row["country_name"]).strip()  # å»é™¤ç©ºæ ¼
                country = db.query(Country).filter(Country.name == country_name).first()
                if not country:
                    # è·å–æ‰€æœ‰å¯ç”¨çš„å›½å®¶åç§°ç”¨äºè°ƒè¯•
                    available_countries = [c.name for c in db.query(Country).all()]
                    logger.warning(f"æ¸¯å£éªŒè¯å¤±è´¥ - ç¬¬{index+2}è¡Œ: å›½å®¶åç§° '{country_name}' ä¸å­˜åœ¨")
                    logger.warning(f"å¯ç”¨çš„å›½å®¶: {available_countries}")
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶åç§°åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨")
                    row_errors.append(f"ğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥å›½å®¶åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥å›½å®¶æ•°æ®")
        
        elif table_name == "companies" and "country_name" in row:
            if not pd.isna(row["country_name"]):
                country_name = str(row["country_name"]).strip()  # å»é™¤ç©ºæ ¼
                country = db.query(Country).filter(Country.name == country_name).first()
                if not country:
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶åç§°åœ¨ç³»ç»Ÿä¸­ä¸å­˜åœ¨")
                    row_errors.append(f"ğŸ’¡ å»ºè®®ï¼šè¯·æ£€æŸ¥å›½å®¶åç§°æ‹¼å†™ï¼Œæˆ–å…ˆå¯¼å…¥å›½å®¶æ•°æ®")
        
        elif table_name == "suppliers" and "country_name" in row:
            if not pd.isna(row["country_name"]):
                country_name = str(row["country_name"]).strip()  # å»é™¤ç©ºæ ¼
                country = db.query(Country).filter(Country.name == country_name).first()
                if not country:
                    # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„å›½å®¶
                    all_countries = db.query(Country.name).all()
                    available_countries = [c[0] for c in all_countries]
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: country_name '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}")
        
        elif table_name == "ships" and "company_name" in row:
            if not pd.isna(row["company_name"]):
                company = db.query(Company).filter(Company.name == row["company_name"]).first()
                if not company:
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: å…¬å¸ '{row['company_name']}' ä¸å­˜åœ¨")
        
        elif table_name == "products":
            # éªŒè¯äº§å“çš„å¤šä¸ªå¤–é”®å…³ç³»
            if "country_name" in row and not pd.isna(row["country_name"]):
                country = db.query(Country).filter(Country.name == row["country_name"]).first()
                if not country:
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶ '{row['country_name']}' ä¸å­˜åœ¨")
            
            if "category_name" in row and not pd.isna(row["category_name"]):
                category = db.query(Category).filter(Category.name == row["category_name"]).first()
                if not category:
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: ç±»åˆ« '{row['category_name']}' ä¸å­˜åœ¨")
            
            if "supplier_name" in row and not pd.isna(row["supplier_name"]):
                supplier = db.query(Supplier).filter(Supplier.name == row["supplier_name"]).first()
                if not supplier:
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: ä¾›åº”å•† '{row['supplier_name']}' ä¸å­˜åœ¨")
            
            if "port_name" in row and not pd.isna(row["port_name"]):
                port = db.query(Port).filter(Port.name == row["port_name"]).first()
                if not port:
                    row_errors.append(f"ç¬¬{index+2}è¡Œ: æ¸¯å£ '{row['port_name']}' ä¸å­˜åœ¨")
        
        if row_errors:
            validation_result["invalid_rows"] += 1
            validation_result["errors"].extend(row_errors)
        else:
            validation_result["valid_rows"] += 1
        
        # æ·»åŠ æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰
        if index < 5:
            # å¤„ç†NaNå€¼ï¼Œè½¬æ¢ä¸ºNoneä»¥ä¾¿JSONåºåˆ—åŒ–
            row_dict = row.to_dict()
            for key, value in row_dict.items():
                if pd.isna(value):
                    row_dict[key] = None
            validation_result["data_preview"].append(row_dict)
    
    return validation_result

def get_table_validation_rules(table_name: str) -> Dict[str, Any]:
    """è·å–è¡¨çš„éªŒè¯è§„åˆ™"""
    rules = {
        "countries": {
            "required_columns": ["name", "code"],
            "unique_columns": ["name", "code"]
        },
        "categories": {
            "required_columns": ["name"],
            "unique_columns": ["name"]
        },
        "ports": {
            "required_columns": ["name", "country_name"],
            "foreign_keys": {"country_name": "countries.name"}
        },
        "companies": {
            "required_columns": ["name", "country_name"],
            "foreign_keys": {"country_name": "countries.name"}
        },
        "suppliers": {
            "required_columns": ["name", "country_name"],
            "foreign_keys": {"country_name": "countries.name"}
        },
        "ships": {
            "required_columns": ["name", "company_name", "capacity"],
            "foreign_keys": {"company_name": "companies.name"}
        },
        "products": {
            "required_columns": ["product_name_en", "country_name", "category_name", "effective_from"],
            "foreign_keys": {
                "country_name": "countries.name",
                "category_name": "categories.name",
                "supplier_name": "suppliers.name",
                "port_name": "ports.name"
            }
        }
    }
    
    return rules.get(table_name)

@router.post("/precheck-data")
async def precheck_file_data(
    file: UploadFile = File(...),
    table_name: str = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """é¢„æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶æ•°æ®ï¼Œè¯†åˆ«æ–°æ•°æ®ã€ç›¸ä¼¼æ•°æ®å’Œé‡å¤æ•°æ®"""

    # éªŒè¯æ–‡ä»¶
    if not file.filename:
        raise HTTPException(status_code=400, detail="æœªé€‰æ‹©æ–‡ä»¶")

    if not validate_file_type(file.filename):
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹")

    if file.size and file.size > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶")

    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        content = await file.read()

        # è§£æExcel/CSVæ–‡ä»¶
        if file.filename.lower().endswith('.csv'):
            df = pd.read_csv(io.StringIO(content.decode('utf-8')))
        else:
            df = pd.read_excel(io.BytesIO(content))

        if df.empty:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–æ•°æ®")

        logger.info(f"å¼€å§‹é¢„æ£€æŸ¥ {table_name} æ•°æ®ï¼Œå…± {len(df)} è¡Œ")

        # æ‰§è¡Œæ•°æ®é¢„æ£€æŸ¥
        precheck_result = precheck_data(table_name, df, db)

        logger.info(f"é¢„æ£€æŸ¥å®Œæˆ: æ–°æ•°æ® {len(precheck_result.new_items)} æ¡ï¼Œ"
                   f"ç›¸ä¼¼æ•°æ® {len(precheck_result.similar_items)} æ¡ï¼Œ"
                   f"é‡å¤æ•°æ® {len(precheck_result.exact_duplicates)} æ¡ï¼Œ"
                   f"é”™è¯¯ {len(precheck_result.validation_errors)} æ¡")

        return {
            "status": "success",
            "message": "æ•°æ®é¢„æ£€æŸ¥å®Œæˆ",
            "precheck_result": precheck_result.to_dict(),
            "total_rows": len(df)
        }

    except Exception as e:
        logger.error(f"æ•°æ®é¢„æ£€æŸ¥å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ•°æ®é¢„æ£€æŸ¥å¤±è´¥: {str(e)}")

@router.post("/validate-file")
async def validate_file(
    file: UploadFile = File(...),
    table_name: str = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """éªŒè¯ä¸Šä¼ çš„æ–‡ä»¶"""
    
    # éªŒè¯æ–‡ä»¶å¤§å°
    if file.size > MAX_FILE_SIZE:
        raise HTTPException(status_code=400, detail="æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆ10MBï¼‰")
    
    # éªŒè¯æ–‡ä»¶ç±»å‹
    if not validate_file_type(file.filename):
        raise HTTPException(status_code=400, detail="ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼Œè¯·ä¸Šä¼  .xlsx, .xls æˆ– .csv æ–‡ä»¶")
    
    try:
        # è¯»å–æ–‡ä»¶å†…å®¹
        file_content = await file.read()
        
        # è§£ææ–‡ä»¶
        df = read_excel_file(file_content, file.filename)
        
        if df.empty:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–æ•°æ®")
        
        # éªŒè¯æ•°æ®
        validation_result = validate_table_data(table_name, df, db)
        
        return {
            "status": "success",
            "message": "æ–‡ä»¶éªŒè¯å®Œæˆ",
            "validation_result": validation_result
        }
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        logger.error(f"æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ–‡ä»¶éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")

@router.post("/upload-products-with-progress")
async def upload_products_with_progress(
    file: UploadFile = File(...),
    table_name: str = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    ä¸“é—¨çš„äº§å“ä¸Šä¼ ç«¯ç‚¹ï¼Œæ”¯æŒè¿›åº¦æ˜¾ç¤º
    """
    if table_name != 'products':
        raise HTTPException(status_code=400, detail="æ­¤ç«¯ç‚¹ä»…æ”¯æŒäº§å“ä¸Šä¼ ")

    # è°ƒç”¨é€šç”¨ä¸Šä¼ é€»è¾‘
    return await upload_data_internal(file, table_name, db, current_user)

@router.post("/upload-data")
async def upload_data(
    file: UploadFile = File(...),
    table_name: str = Form(...),
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    """
    é€šç”¨æ•°æ®ä¸Šä¼ ç«¯ç‚¹
    """
    return await upload_data_internal(file, table_name, db, current_user)

async def upload_data_internal(
    file: UploadFile,
    table_name: str,
    db: Session,
    current_user: User
):
    """ä¸Šä¼ å¹¶å¯¼å…¥æ•°æ®åˆ°æ•°æ®åº“ - åŸå­æ€§äº‹åŠ¡ç‰ˆæœ¬"""

    try:
        # è¯»å–æ–‡ä»¶
        file_content = await file.read()
        df = read_excel_file(file_content, file.filename)

        if df.empty:
            raise HTTPException(status_code=400, detail="æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è¯»å–æ•°æ®")

        logger.info(f"å¼€å§‹åŸå­æ€§å¯¼å…¥ {table_name} æ•°æ®ï¼Œå…± {len(df)} è¡Œ")

        # é˜¶æ®µ1: æ•°æ®é¢„éªŒè¯
        is_valid, validation_result = validate_all_data_before_import(table_name, df, db)

        if not is_valid:
            logger.warning(f"æ•°æ®éªŒè¯å¤±è´¥: {len(validation_result.errors)} ä¸ªé”™è¯¯")
            return {
                "status": "validation_failed",
                "message": "æ•°æ®éªŒè¯å¤±è´¥ï¼Œè¯·ä¿®å¤é”™è¯¯åé‡æ–°ä¸Šä¼ ",
                "validation_result": validation_result.to_dict()
            }

        # é˜¶æ®µ2: åŸå­æ€§æ‰¹é‡å¯¼å…¥
        import_result = import_table_data_atomic(table_name, df, db)

        logger.info(f"å¯¼å…¥å®Œæˆ: æˆåŠŸ {import_result.success_count} è¡Œï¼Œè·³è¿‡ {import_result.skipped_count} è¡Œ")

        return {
            "status": "success",
            "message": "æ•°æ®å¯¼å…¥æˆåŠŸ",
            "import_result": import_result.to_dict()
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        # ä¸éœ€è¦åœ¨è¿™é‡Œå›æ»šï¼Œimport_table_data_atomicå·²ç»å¤„ç†äº†
        raise HTTPException(status_code=500, detail=f"æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")

def import_table_data_atomic(table_name: str, df: pd.DataFrame, db: Session, progress_callback=None) -> ImportResult:
    """
    åŸå­æ€§æ•°æ®å¯¼å…¥ - é€è¡Œæäº¤æ¨¡å¼ï¼Œé¿å…æ‰¹é‡INSERTé—®é¢˜
    """
    result = ImportResult()

    try:
        # è·å–é‡å¤æ•°æ®å¤„ç†ç­–ç•¥
        strategy = DUPLICATE_STRATEGIES.get(table_name, DuplicateHandlingStrategy.ERROR)

        logger.info(f"å¼€å§‹æ•°æ®å¯¼å…¥ {table_name}ï¼Œç­–ç•¥: {strategy.value}ï¼Œä½¿ç”¨é€è¡Œæäº¤æ¨¡å¼")

        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„åŠ è½½æ‰€æœ‰å¤–é”®æ•°æ®
        foreign_key_maps = preload_foreign_key_data(table_name, db)
        logger.info(f"å¤–é”®æ•°æ®é¢„åŠ è½½å®Œæˆï¼ŒåŒ…å« {sum(len(v) for v in foreign_key_maps.values())} æ¡è®°å½•")

        # é€è¡Œå¤„ç†æ•°æ®å¹¶ç«‹å³æäº¤
        for index, row in df.iterrows():
            try:
                row_result = process_single_row_atomic_optimized(table_name, row, index + 2, db, strategy, foreign_key_maps)

                if row_result["status"] == "success":
                    # ç«‹å³æäº¤è¿™ä¸€è¡Œçš„æ›´æ”¹
                    db.commit()
                    result.success_count += 1
                    logger.debug(f"ç¬¬{index+2}è¡Œæ•°æ®æäº¤æˆåŠŸ")
                elif row_result["status"] == "skipped":
                    result.skipped_count += 1
                    result.skipped_items.append(row_result["message"])
                elif row_result["status"] == "error":
                    result.error_count += 1
                    result.errors.append(row_result["message"])

                    # å¦‚æœç­–ç•¥æ˜¯ERRORï¼Œç«‹å³æŠ›å‡ºå¼‚å¸¸
                    if strategy == DuplicateHandlingStrategy.ERROR:
                        raise Exception(f"æ•°æ®å¯¼å…¥å¤±è´¥: {row_result['message']}")

            except Exception as e:
                # å›æ»šå½“å‰è¡Œçš„æ›´æ”¹
                db.rollback()
                logger.error(f"å¤„ç†ç¬¬{index+2}è¡Œæ—¶å‘ç”Ÿé”™è¯¯: {e}")

                # å¦‚æœæ˜¯ERRORç­–ç•¥ï¼Œåœæ­¢å¤„ç†å¹¶æŠ›å‡ºå¼‚å¸¸
                if strategy == DuplicateHandlingStrategy.ERROR:
                    result.errors.append(f"ç¬¬{index+2}è¡Œå¯¼å…¥å¤±è´¥ï¼Œæ‰€æœ‰æ›´æ”¹å·²å›æ»š: {str(e)}")
                    result.error_count = len(df)
                    result.success_count = 0
                    result.skipped_count = 0
                    raise e
                else:
                    # å¦‚æœæ˜¯å…¶ä»–ç­–ç•¥ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†
                    result.error_count += 1
                    result.errors.append(f"ç¬¬{index+2}è¡Œ: {str(e)}")

        logger.info(f"æ•°æ®å¯¼å…¥å®Œæˆ: æˆåŠŸ {result.success_count} è¡Œï¼Œè·³è¿‡ {result.skipped_count} è¡Œï¼Œé”™è¯¯ {result.error_count} è¡Œ")

    except Exception as e:
        logger.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        # é”™è¯¯ä¿¡æ¯å·²åœ¨ä¸Šé¢å¤„ç†
        if not result.errors:
            result.errors.append(f"å¯¼å…¥å¤±è´¥: {str(e)}")
            result.error_count = len(df)
            result.success_count = 0
            result.skipped_count = 0
        raise e

    return result


def import_table_data_batch(table_name: str, df: pd.DataFrame, db: Session, batch_size: int = 10) -> ImportResult:
    """
    æ‰¹é‡æ•°æ®å¯¼å…¥ - åˆ†æ‰¹æäº¤æ¨¡å¼ï¼Œé¿å…å¤§æ‰¹é‡INSERTé—®é¢˜
    """
    result = ImportResult()

    try:
        # è·å–é‡å¤æ•°æ®å¤„ç†ç­–ç•¥
        strategy = DUPLICATE_STRATEGIES.get(table_name, DuplicateHandlingStrategy.ERROR)

        logger.info(f"å¼€å§‹æ•°æ®å¯¼å…¥ {table_name}ï¼Œç­–ç•¥: {strategy.value}ï¼Œæ‰¹é‡å¤§å°: {batch_size}")

        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šé¢„åŠ è½½æ‰€æœ‰å¤–é”®æ•°æ®
        foreign_key_maps = preload_foreign_key_data(table_name, db)
        logger.info(f"å¤–é”®æ•°æ®é¢„åŠ è½½å®Œæˆï¼ŒåŒ…å« {sum(len(v) for v in foreign_key_maps.values())} æ¡è®°å½•")

        # åˆ†æ‰¹å¤„ç†æ•°æ®
        total_rows = len(df)
        for batch_start in range(0, total_rows, batch_size):
            batch_end = min(batch_start + batch_size, total_rows)
            batch_df = df.iloc[batch_start:batch_end]

            logger.info(f"å¤„ç†æ‰¹æ¬¡ {batch_start//batch_size + 1}: ç¬¬{batch_start+1}-{batch_end}è¡Œ")

            try:
                # å¤„ç†å½“å‰æ‰¹æ¬¡çš„æ‰€æœ‰è¡Œ
                batch_success = 0
                for index, row in batch_df.iterrows():
                    row_result = process_single_row_atomic_optimized(table_name, row, index + 2, db, strategy, foreign_key_maps)

                    if row_result["status"] == "success":
                        batch_success += 1
                    elif row_result["status"] == "skipped":
                        result.skipped_count += 1
                        result.skipped_items.append(row_result["message"])
                    elif row_result["status"] == "error":
                        result.error_count += 1
                        result.errors.append(row_result["message"])

                        # å¦‚æœç­–ç•¥æ˜¯ERRORï¼Œç«‹å³æŠ›å‡ºå¼‚å¸¸å›æ»šæ•´ä¸ªæ‰¹æ¬¡
                        if strategy == DuplicateHandlingStrategy.ERROR:
                            raise Exception(f"æ•°æ®å¯¼å…¥å¤±è´¥: {row_result['message']}")

                # æäº¤å½“å‰æ‰¹æ¬¡
                db.commit()
                result.success_count += batch_success
                logger.info(f"æ‰¹æ¬¡ {batch_start//batch_size + 1} æäº¤æˆåŠŸï¼Œå¤„ç† {batch_success} è¡Œ")

            except Exception as e:
                # å›æ»šå½“å‰æ‰¹æ¬¡
                db.rollback()
                logger.error(f"æ‰¹æ¬¡ {batch_start//batch_size + 1} å¤„ç†å¤±è´¥: {e}")

                # å¦‚æœæ˜¯ERRORç­–ç•¥ï¼Œåœæ­¢å¤„ç†
                if strategy == DuplicateHandlingStrategy.ERROR:
                    result.errors.append(f"æ‰¹æ¬¡å¯¼å…¥å¤±è´¥ï¼Œæ‰€æœ‰æ›´æ”¹å·²å›æ»š: {str(e)}")
                    result.error_count = len(df)
                    result.success_count = 0
                    result.skipped_count = 0
                    raise e

        logger.info(f"æ•°æ®å¯¼å…¥å®Œæˆ: æˆåŠŸ {result.success_count} è¡Œï¼Œè·³è¿‡ {result.skipped_count} è¡Œï¼Œé”™è¯¯ {result.error_count} è¡Œ")

    except Exception as e:
        logger.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {e}")
        if not result.errors:
            result.errors.append(f"å¯¼å…¥å¤±è´¥: {str(e)}")

    return result




def preload_foreign_key_data(table_name: str, db: Session) -> Dict[str, Dict[str, int]]:
    """
    é¢„åŠ è½½å¤–é”®æ•°æ®åˆ°å†…å­˜æ˜ å°„è¡¨
    ğŸš€ æ€§èƒ½ä¼˜åŒ–ï¼šé¿å…åœ¨å¾ªç¯ä¸­é‡å¤æŸ¥è¯¢æ•°æ®åº“
    """
    foreign_key_maps = {}

    try:
        if table_name == "products":
            # é¢„åŠ è½½äº§å“è¡¨éœ€è¦çš„æ‰€æœ‰å¤–é”®æ•°æ®
            logger.info("æ­£åœ¨é¢„åŠ è½½äº§å“å¤–é”®æ•°æ®...")

            # åŠ è½½å›½å®¶æ•°æ®
            countries_map = {}
            for country in db.query(Country).all():
                countries_map[country.name] = country.id
            foreign_key_maps["countries"] = countries_map
            logger.info(f"é¢„åŠ è½½å›½å®¶æ•°æ®: {len(countries_map)} æ¡")

            # åŠ è½½ç±»åˆ«æ•°æ®
            categories_map = {}
            for category in db.query(Category).all():
                categories_map[category.name] = category.id
            foreign_key_maps["categories"] = categories_map
            logger.info(f"é¢„åŠ è½½ç±»åˆ«æ•°æ®: {len(categories_map)} æ¡")

            # åŠ è½½ä¾›åº”å•†æ•°æ®
            suppliers_map = {}
            for supplier in db.query(Supplier).all():
                suppliers_map[supplier.name] = supplier.id
            foreign_key_maps["suppliers"] = suppliers_map
            logger.info(f"é¢„åŠ è½½ä¾›åº”å•†æ•°æ®: {len(suppliers_map)} æ¡")

            # åŠ è½½æ¸¯å£æ•°æ®
            ports_map = {}
            for port in db.query(Port).all():
                ports_map[port.name] = port.id
            foreign_key_maps["ports"] = ports_map
            logger.info(f"é¢„åŠ è½½æ¸¯å£æ•°æ®: {len(ports_map)} æ¡")

        elif table_name == "suppliers":
            # ä¾›åº”å•†è¡¨åªéœ€è¦å›½å®¶æ•°æ®
            countries_map = {}
            for country in db.query(Country).all():
                countries_map[country.name] = country.id
            foreign_key_maps["countries"] = countries_map

        elif table_name == "ports":
            # æ¸¯å£è¡¨åªéœ€è¦å›½å®¶æ•°æ®
            countries_map = {}
            for country in db.query(Country).all():
                countries_map[country.name] = country.id
            foreign_key_maps["countries"] = countries_map

        elif table_name == "companies":
            # å…¬å¸è¡¨åªéœ€è¦å›½å®¶æ•°æ®
            countries_map = {}
            for country in db.query(Country).all():
                countries_map[country.name] = country.id
            foreign_key_maps["countries"] = countries_map

        elif table_name == "ships":
            # èˆ¹èˆ¶è¡¨åªéœ€è¦å…¬å¸æ•°æ®
            companies_map = {}
            for company in db.query(Company).all():
                companies_map[company.name] = company.id
            foreign_key_maps["companies"] = companies_map

        logger.info(f"å¤–é”®æ•°æ®é¢„åŠ è½½å®Œæˆ: {table_name}")

    except Exception as e:
        logger.error(f"é¢„åŠ è½½å¤–é”®æ•°æ®å¤±è´¥: {str(e)}")
        # å¦‚æœé¢„åŠ è½½å¤±è´¥ï¼Œè¿”å›ç©ºæ˜ å°„ï¼Œå›é€€åˆ°åŸæœ‰æŸ¥è¯¢æ–¹å¼
        foreign_key_maps = {}

    return foreign_key_maps

def process_single_row_atomic_optimized(table_name: str, row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy, foreign_key_maps: Dict[str, Dict[str, int]]) -> Dict[str, str]:
    """å¤„ç†å•è¡Œæ•°æ®çš„åŸå­æ€§æ“ä½œ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨é¢„åŠ è½½çš„å¤–é”®æ•°æ®"""

    try:
        if table_name == "countries":
            return process_country_row(row, row_number, db, strategy)
        elif table_name == "categories":
            return process_category_row(row, row_number, db, strategy)
        elif table_name == "ports":
            return process_port_row_optimized(row, row_number, db, strategy, foreign_key_maps)
        elif table_name == "companies":
            return process_company_row_optimized(row, row_number, db, strategy, foreign_key_maps)
        elif table_name == "suppliers":
            return process_supplier_row_optimized(row, row_number, db, strategy, foreign_key_maps)
        elif table_name == "ships":
            return process_ship_row_optimized(row, row_number, db, strategy, foreign_key_maps)
        elif table_name == "products":
            return process_product_row_optimized(row, row_number, db, strategy, foreign_key_maps)
        else:
            return {"status": "error", "message": f"ä¸æ”¯æŒçš„è¡¨ç±»å‹: {table_name}"}

    except Exception as e:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å¤„ç†å¤±è´¥ - {str(e)}"}

def process_single_row_atomic(table_name: str, row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†å•è¡Œæ•°æ®çš„åŸå­æ€§æ“ä½œ"""

    try:
        if table_name == "countries":
            return process_country_row(row, row_number, db, strategy)
        elif table_name == "categories":
            return process_category_row(row, row_number, db, strategy)
        elif table_name == "ports":
            return process_port_row(row, row_number, db, strategy)
        elif table_name == "companies":
            return process_company_row(row, row_number, db, strategy)
        elif table_name == "suppliers":
            return process_supplier_row(row, row_number, db, strategy)
        elif table_name == "ships":
            return process_ship_row(row, row_number, db, strategy)
        elif table_name == "products":
            return process_product_row(row, row_number, db, strategy)
        else:
            return {"status": "error", "message": f"ä¸æ”¯æŒçš„è¡¨ç±»å‹: {table_name}"}

    except Exception as e:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œå¤„ç†å¤±è´¥: {str(e)}"}

def process_country_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†å›½å®¶æ•°æ®è¡Œ"""
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    existing = db.query(Country).filter(
        (Country.name == row["name"]) | (Country.code == row["code"])
    ).first()

    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['name']}' æˆ–ä»£ç  '{row['code']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['name']}' æˆ–ä»£ç  '{row['code']}' å·²å­˜åœ¨"}

    # åˆ›å»ºæ–°è®°å½•
    country = Country(
        name=row["name"],
        code=row["code"],
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(country)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_category_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†ç±»åˆ«æ•°æ®è¡Œ"""
    existing = db.query(Category).filter(Category.name == row["name"]).first()

    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: ç±»åˆ« '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ç±»åˆ« '{row['name']}' å·²å­˜åœ¨"}

    category = Category(
        name=row["name"],
        code=row.get("code") if not pd.isna(row.get("code")) else None,
        description=row.get("description") if not pd.isna(row.get("description")) else None,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(category)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: ç±»åˆ« '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_port_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†æ¸¯å£æ•°æ®è¡Œ"""
    # æŸ¥æ‰¾å›½å®¶
    country_name = str(row["country_name"]).strip()
    country = db.query(Country).filter(Country.name == country_name).first()
    if not country:
        # è·å–è°ƒè¯•ä¿¡æ¯
        all_countries = db.query(Country.name).all()
        available_countries = [c[0] for c in all_countries]
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}"}

    # æ£€æŸ¥æ¸¯å£åç§°æ˜¯å¦å·²å­˜åœ¨
    existing = db.query(Port).filter(Port.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['name']}' å·²å­˜åœ¨"}

    # å¤„ç†codeå­—æ®µ - æ£€æŸ¥å”¯ä¸€æ€§
    port_code = row.get("code")
    if port_code and str(port_code).strip():
        port_code = str(port_code).strip()
        # æ£€æŸ¥codeæ˜¯å¦å·²å­˜åœ¨
        existing_code = db.query(Port).filter(Port.code == port_code).first()
        if existing_code:
            if strategy == DuplicateHandlingStrategy.SKIP:
                return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ä»£ç  '{port_code}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
            else:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ä»£ç  '{port_code}' å·²å­˜åœ¨"}
    else:
        port_code = None  # ç¡®ä¿ç©ºå€¼ä¸ºNone

    port = Port(
        name=row["name"],
        code=port_code,
        country_id=country.id,
        location=row.get("location"),
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(port)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_company_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†å…¬å¸æ•°æ®è¡Œ"""
    # æŸ¥æ‰¾å›½å®¶
    country_name = str(row["country_name"]).strip()
    country = db.query(Country).filter(Country.name == country_name).first()
    if not country:
        # è·å–è°ƒè¯•ä¿¡æ¯
        all_countries = db.query(Country.name).all()
        available_countries = [c[0] for c in all_countries]
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}"}

    existing = db.query(Company).filter(Company.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['name']}' å·²å­˜åœ¨"}

    # å®‰å…¨å¤„ç†æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µ
    def safe_string_field(value):
        if value is None or pd.isna(value):
            return None
        return str(value).strip() if str(value).strip() else None

    contact_value = safe_string_field(row.get("contact"))
    email_value = safe_string_field(row.get("email"))
    phone_value = safe_string_field(row.get("phone"))

    company = Company(
        name=row["name"],
        country_id=country.id,
        contact=contact_value,
        email=email_value,
        phone=phone_value,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(company)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_supplier_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†ä¾›åº”å•†æ•°æ®è¡Œ"""
    # æŸ¥æ‰¾å›½å®¶
    country_name = str(row["country_name"]).strip()  # å»é™¤ç©ºæ ¼
    country = db.query(Country).filter(Country.name == country_name).first()
    if not country:
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„å›½å®¶
        all_countries = db.query(Country.name).all()
        available_countries = [c[0] for c in all_countries]
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}"}

    existing = db.query(Supplier).filter(Supplier.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['name']}' å·²å­˜åœ¨"}

    # å®‰å…¨å¤„ç†æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µ
    def safe_string_field(value):
        if value is None or pd.isna(value):
            return None
        return str(value).strip() if str(value).strip() else None

    contact_value = safe_string_field(row.get("contact"))
    email_value = safe_string_field(row.get("email"))
    phone_value = safe_string_field(row.get("phone"))

    supplier = Supplier(
        name=row["name"],
        country_id=country.id,
        contact=contact_value,
        email=email_value,
        phone=phone_value,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(supplier)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_ship_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†èˆ¹èˆ¶æ•°æ®è¡Œ"""
    # æŸ¥æ‰¾å…¬å¸
    company = db.query(Company).filter(Company.name == row["company_name"]).first()
    if not company:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['company_name']}' ä¸å­˜åœ¨"}

    existing = db.query(Ship).filter(Ship.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: èˆ¹èˆ¶ '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: èˆ¹èˆ¶ '{row['name']}' å·²å­˜åœ¨"}

    ship = Ship(
        name=row["name"],
        company_id=company.id,
        ship_type=row.get("ship_type"),
        capacity=int(row["capacity"]) if row.get("capacity") else None,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(ship)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: èˆ¹èˆ¶ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_product_row(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy) -> Dict[str, str]:
    """å¤„ç†äº§å“æ•°æ®è¡Œ - å®Œæ•´ç‰ˆæœ¬"""
    try:
        # æŸ¥æ‰¾å¿…è¦çš„å¤–é”®
        country_name = str(row["country_name"]).strip()
        country = db.query(Country).filter(Country.name == country_name).first()
        if not country:
            all_countries = db.query(Country.name).all()
            available_countries = [c[0] for c in all_countries]
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}"}

        category_name = str(row["category_name"]).strip()
        category = db.query(Category).filter(Category.name == category_name).first()
        if not category:
            all_categories = db.query(Category.name).all()
            available_categories = [c[0] for c in all_categories]
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ç±»åˆ« '{category_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨ç±»åˆ«: {available_categories}"}

        # æ£€æŸ¥äº§å“æ˜¯å¦å·²å­˜åœ¨
        existing = db.query(Product).filter(Product.product_name_en == row["product_name_en"]).first()
        if existing:
            if strategy == DuplicateHandlingStrategy.SKIP:
                return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: äº§å“ '{row['product_name_en']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
            else:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: äº§å“ '{row['product_name_en']}' å·²å­˜åœ¨"}

        # å¤„ç†å¯é€‰çš„å¤–é”®å…³ç³»
        supplier_id = None
        if row.get("supplier_name") and not pd.isna(row["supplier_name"]):
            supplier_name = str(row["supplier_name"]).strip()
            supplier = db.query(Supplier).filter(Supplier.name == supplier_name).first()
            if supplier:
                supplier_id = supplier.id
            else:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{supplier_name}' ä¸å­˜åœ¨"}

        port_id = None
        if row.get("port_name") and not pd.isna(row["port_name"]):
            port_name = str(row["port_name"]).strip()
            port = db.query(Port).filter(Port.name == port_name).first()
            if port:
                port_id = port.id
            else:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{port_name}' ä¸å­˜åœ¨"}

        # å®‰å…¨å¤„ç†å­—ç¬¦ä¸²å­—æ®µ
        def safe_string_field(value):
            if value is None or pd.isna(value):
                return None
            return str(value).strip() if str(value).strip() else None

        code_value = safe_string_field(row.get("code"))
        unit_value = safe_string_field(row.get("unit"))
        currency_value = safe_string_field(row.get("currency"))
        unit_size_value = safe_string_field(row.get("unit_size"))
        brand_value = safe_string_field(row.get("brand"))
        country_of_origin_value = safe_string_field(row.get("country_of_origin"))

        # å¤„ç†å­—æ®µ
        pack_size_value = None
        if row.get("pack_size") and not pd.isna(row["pack_size"]):
            # pack_size ç°åœ¨æ”¯æŒå­—ç¬¦ä¸²æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å€¼
            pack_size_value = str(row["pack_size"]).strip()

        price_value = None
        if row.get("price") and not pd.isna(row["price"]):
            try:
                price_value = float(row["price"])
                if price_value < 0:
                    return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: price (ä»·æ ¼) ä¸èƒ½ä¸ºè´Ÿæ•°"}
            except (ValueError, TypeError):
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: price (ä»·æ ¼) æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä¸ºæ•°å­—"}

        # å¤„ç†æ—¥æœŸå­—æ®µ
        from datetime import datetime, timedelta
        effective_from_value = None
        effective_to_value = None

        if row.get("effective_from") and not pd.isna(row["effective_from"]):
            try:
                effective_from_value = pd.to_datetime(row["effective_from"]).to_pydatetime()
            except Exception as e:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: èµ·å§‹æ—¥æœŸæ ¼å¼é”™è¯¯ - {str(e)}"}

        if row.get("effective_to") and not pd.isna(row["effective_to"]):
            try:
                effective_to_value = pd.to_datetime(row["effective_to"]).to_pydatetime()
            except Exception as e:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯ - {str(e)}"}
        elif effective_from_value:
            # å¦‚æœæ²¡æœ‰ç»“æŸæ—¥æœŸï¼Œè‡ªåŠ¨è®¾ç½®ä¸ºèµ·å§‹æ—¥æœŸ+3ä¸ªæœˆ
            effective_to_value = effective_from_value + timedelta(days=90)

        # éªŒè¯æ—¥æœŸèŒƒå›´
        if effective_from_value and effective_to_value:
            if effective_to_value < effective_from_value:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ç»“æŸæ—¥æœŸä¸èƒ½æ—©äºèµ·å§‹æ—¥æœŸ"}

        # åˆ›å»ºäº§å“
        product = Product(
            product_name_en=row["product_name_en"],
            product_name_jp=row.get("product_name_jp"),
            code=code_value,
            country_id=country.id,
            category_id=category.id,
            supplier_id=supplier_id,
            port_id=port_id,
            unit=unit_value,
            price=price_value,
            currency=currency_value,
            unit_size=unit_size_value,
            pack_size=pack_size_value,
            brand=brand_value,
            country_of_origin=country_of_origin_value,
            effective_from=effective_from_value,
            effective_to=effective_to_value,
            status=str(row.get("status", "true")).lower() == "true"
        )
        db.add(product)
        return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: äº§å“ '{row['product_name_en']}' åˆ›å»ºæˆåŠŸ"}

    except Exception as e:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å¤„ç†å¤±è´¥ - {str(e)}"}

def process_product_row_optimized(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy, foreign_key_maps: Dict[str, Dict[str, int]]) -> Dict[str, str]:
    """å¤„ç†äº§å“æ•°æ®è¡Œ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨é¢„åŠ è½½çš„å¤–é”®æ•°æ®"""

    try:
        # ğŸ”¥ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨é¢„åŠ è½½çš„æ˜ å°„è¡¨ï¼Œé¿å…æ•°æ®åº“æŸ¥è¯¢

        # æŸ¥æ‰¾å›½å®¶IDï¼ˆä»å†…å­˜æ˜ å°„è¡¨ï¼‰
        country_id = foreign_key_maps.get("countries", {}).get(row["country_name"])
        if not country_id:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['country_name']}' ä¸å­˜åœ¨"}

        # æŸ¥æ‰¾ç±»åˆ«IDï¼ˆä»å†…å­˜æ˜ å°„è¡¨ï¼‰
        category_id = foreign_key_maps.get("categories", {}).get(row["category_name"])
        if not category_id:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ç±»åˆ« '{row['category_name']}' ä¸å­˜åœ¨"}

        # æŸ¥æ‰¾ä¾›åº”å•†IDï¼ˆä»å†…å­˜æ˜ å°„è¡¨ï¼Œå¯é€‰ï¼‰
        supplier_id = None
        if row.get("supplier_name") and not pd.isna(row["supplier_name"]):
            supplier_id = foreign_key_maps.get("suppliers", {}).get(row["supplier_name"])
            if not supplier_id:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['supplier_name']}' ä¸å­˜åœ¨"}

        # æŸ¥æ‰¾æ¸¯å£IDï¼ˆä»å†…å­˜æ˜ å°„è¡¨ï¼Œå¯é€‰ï¼‰
        port_id = None
        if row.get("port_name") and not pd.isna(row["port_name"]):
            port_id = foreign_key_maps.get("ports", {}).get(row["port_name"])
            if not port_id:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['port_name']}' ä¸å­˜åœ¨"}

        # æ£€æŸ¥äº§å“æ˜¯å¦å·²å­˜åœ¨
        existing = db.query(Product).filter(Product.product_name_en == row["product_name_en"]).first()
        if existing:
            if strategy == DuplicateHandlingStrategy.SKIP:
                return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: äº§å“ '{row['product_name_en']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
            else:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: äº§å“ '{row['product_name_en']}' å·²å­˜åœ¨"}

        # å¤„ç†å…¶ä»–å­—æ®µ
        code_value = row.get("code")
        if code_value and not pd.isna(code_value):
            code_value = str(code_value).strip()
        else:
            code_value = None

        unit_value = row.get("unit")
        if unit_value and not pd.isna(unit_value):
            unit_value = str(unit_value).strip()
        else:
            unit_value = None

        price_value = None
        if row.get("price") and not pd.isna(row["price"]):
            try:
                price_value = float(row["price"])
                if price_value < 0:
                    return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: price (ä»·æ ¼) ä¸èƒ½ä¸ºè´Ÿæ•°"}
            except (ValueError, TypeError):
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: price (ä»·æ ¼) æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä¸ºæ•°å­—"}

        currency_value = row.get("currency")
        if currency_value and not pd.isna(currency_value):
            currency_value = str(currency_value).strip()
        else:
            currency_value = None

        unit_size_value = row.get("unit_size")
        if unit_size_value and not pd.isna(unit_size_value):
            unit_size_value = str(unit_size_value).strip()
        else:
            unit_size_value = None

        # pack_size ç°åœ¨æ”¯æŒå­—ç¬¦ä¸²æ ¼å¼
        pack_size_value = None
        if row.get("pack_size") and not pd.isna(row["pack_size"]):
            pack_size_value = str(row["pack_size"]).strip()

        brand_value = row.get("brand")
        if brand_value and not pd.isna(brand_value):
            brand_value = str(brand_value).strip()
        else:
            brand_value = None

        country_of_origin_value = row.get("country_of_origin")
        if country_of_origin_value and not pd.isna(country_of_origin_value):
            country_of_origin_value = str(country_of_origin_value).strip()
        else:
            country_of_origin_value = None

        # å¤„ç†æ—¥æœŸå­—æ®µ
        effective_from_value = None
        if row.get("effective_from") and not pd.isna(row["effective_from"]):
            try:
                if isinstance(row["effective_from"], str):
                    effective_from_value = datetime.strptime(row["effective_from"], "%Y-%m-%d").date()
                else:
                    effective_from_value = row["effective_from"]
            except (ValueError, TypeError):
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: effective_from æ—¥æœŸæ ¼å¼é”™è¯¯"}

        effective_to_value = None
        if row.get("effective_to") and not pd.isna(row["effective_to"]):
            try:
                if isinstance(row["effective_to"], str):
                    effective_to_value = datetime.strptime(row["effective_to"], "%Y-%m-%d").date()
                else:
                    effective_to_value = row["effective_to"]
            except (ValueError, TypeError):
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: effective_to æ—¥æœŸæ ¼å¼é”™è¯¯"}

        # åˆ›å»ºäº§å“
        product = Product(
            product_name_en=row["product_name_en"],
            product_name_jp=row.get("product_name_jp"),
            code=code_value,
            country_id=country_id,
            category_id=category_id,
            supplier_id=supplier_id,
            port_id=port_id,
            unit=unit_value,
            price=price_value,
            currency=currency_value,
            unit_size=unit_size_value,
            pack_size=pack_size_value,
            brand=brand_value,
            country_of_origin=country_of_origin_value,
            effective_from=effective_from_value,
            effective_to=effective_to_value,
            status=str(row.get("status", "true")).lower() == "true"
        )
        db.add(product)
        return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: äº§å“ '{row['product_name_en']}' åˆ›å»ºæˆåŠŸ"}

    except Exception as e:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å¤„ç†å¤±è´¥ - {str(e)}"}

def process_port_row_optimized(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy, foreign_key_maps: Dict[str, Dict[str, int]]) -> Dict[str, str]:
    """å¤„ç†æ¸¯å£æ•°æ®è¡Œ - ä¼˜åŒ–ç‰ˆæœ¬"""
    # ä½¿ç”¨é¢„åŠ è½½çš„å›½å®¶æ•°æ®
    country_id = foreign_key_maps.get("countries", {}).get(row["country_name"])
    if not country_id:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['country_name']}' ä¸å­˜åœ¨"}

    existing = db.query(Port).filter(Port.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['name']}' å·²å­˜åœ¨"}

    port_code = row.get("code")
    if port_code and str(port_code).strip():
        port_code = str(port_code).strip()
        existing_code = db.query(Port).filter(Port.code == port_code).first()
        if existing_code:
            if strategy == DuplicateHandlingStrategy.SKIP:
                return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ä»£ç  '{port_code}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
            else:
                return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ä»£ç  '{port_code}' å·²å­˜åœ¨"}
    else:
        port_code = None

    port = Port(
        name=row["name"],
        code=port_code,
        country_id=country_id,
        location=row.get("location"),
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(port)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: æ¸¯å£ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_company_row_optimized(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy, foreign_key_maps: Dict[str, Dict[str, int]]) -> Dict[str, str]:
    """å¤„ç†å…¬å¸æ•°æ®è¡Œ - ä¼˜åŒ–ç‰ˆæœ¬"""
    # ä½¿ç”¨é¢„åŠ è½½çš„å›½å®¶æ•°æ®
    country_id = foreign_key_maps.get("countries", {}).get(row["country_name"])
    if not country_id:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['country_name']}' ä¸å­˜åœ¨"}

    existing = db.query(Company).filter(Company.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['name']}' å·²å­˜åœ¨"}

    company = Company(
        name=row["name"],
        country_id=country_id,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(company)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_supplier_row_optimized(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy, foreign_key_maps: Dict[str, Dict[str, int]]) -> Dict[str, str]:
    """å¤„ç†ä¾›åº”å•†æ•°æ®è¡Œ - ä¼˜åŒ–ç‰ˆæœ¬"""
    # ä½¿ç”¨é¢„åŠ è½½çš„å›½å®¶æ•°æ®
    country_id = foreign_key_maps.get("countries", {}).get(row["country_name"])
    if not country_id:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å›½å®¶ '{row['country_name']}' ä¸å­˜åœ¨"}

    existing = db.query(Supplier).filter(Supplier.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['name']}' å·²å­˜åœ¨"}

    phone_value = row.get("phone")
    if phone_value is not None and not pd.isna(phone_value):
        phone_value = str(phone_value)
    else:
        phone_value = None

    supplier = Supplier(
        name=row["name"],
        country_id=country_id,
        contact=row.get("contact"),
        email=row.get("email"),
        phone=phone_value,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(supplier)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: ä¾›åº”å•† '{row['name']}' åˆ›å»ºæˆåŠŸ"}

def process_ship_row_optimized(row: pd.Series, row_number: int, db: Session, strategy: DuplicateHandlingStrategy, foreign_key_maps: Dict[str, Dict[str, int]]) -> Dict[str, str]:
    """å¤„ç†èˆ¹èˆ¶æ•°æ®è¡Œ - ä¼˜åŒ–ç‰ˆæœ¬"""
    # ä½¿ç”¨é¢„åŠ è½½çš„å…¬å¸æ•°æ®
    company_id = foreign_key_maps.get("companies", {}).get(row["company_name"])
    if not company_id:
        return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: å…¬å¸ '{row['company_name']}' ä¸å­˜åœ¨"}

    existing = db.query(Ship).filter(Ship.name == row["name"]).first()
    if existing:
        if strategy == DuplicateHandlingStrategy.SKIP:
            return {"status": "skipped", "message": f"ç¬¬{row_number}è¡Œ: èˆ¹èˆ¶ '{row['name']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡"}
        else:
            return {"status": "error", "message": f"ç¬¬{row_number}è¡Œ: èˆ¹èˆ¶ '{row['name']}' å·²å­˜åœ¨"}

    ship = Ship(
        name=row["name"],
        company_id=company_id,
        status=str(row.get("status", "true")).lower() == "true"
    )
    db.add(ship)
    return {"status": "success", "message": f"ç¬¬{row_number}è¡Œ: èˆ¹èˆ¶ '{row['name']}' åˆ›å»ºæˆåŠŸ"}

async def import_table_data(table_name: str, df: pd.DataFrame, db: Session) -> Dict[str, Any]:
    """å¯¼å…¥æ•°æ®åˆ°æŒ‡å®šè¡¨"""

    success_count = 0
    error_count = 0
    skipped_count = 0  # è·³è¿‡çš„é‡å¤æ•°æ®è®¡æ•°
    errors = []
    skipped_items = []  # è·³è¿‡çš„é¡¹ç›®åˆ—è¡¨
    
    try:
        for index, row in df.iterrows():
            try:
                if table_name == "countries":
                    # æ£€æŸ¥å¿…å¡«å­—æ®µ
                    if pd.isna(row["name"]) or str(row["name"]).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: name ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    if pd.isna(row["code"]) or str(row["code"]).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: code ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(Country).filter(
                        (Country.name == row["name"]) | (Country.code == row["code"])
                    ).first()

                    if not existing:
                        country = Country(
                            name=row["name"],
                            code=row["code"],
                            status=str(row.get("status", "true")).lower() == "true"
                        )
                        db.add(country)
                        success_count += 1
                    else:
                        # é‡å¤æ•°æ®è·³è¿‡ï¼Œä¸å†ä½œä¸ºé”™è¯¯
                        skipped_count += 1
                        skipped_items.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶ '{row['name']}' æˆ–ä»£ç  '{row['code']}' å·²å­˜åœ¨ï¼Œå·²è·³è¿‡")
                
                elif table_name == "categories":
                    # æ£€æŸ¥å¿…å¡«å­—æ®µ
                    if pd.isna(row["name"]) or str(row["name"]).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: name ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    existing = db.query(Category).filter(Category.name == row["name"]).first()

                    if not existing:
                        category = Category(
                            name=row["name"],
                            code=row.get("code") if not pd.isna(row.get("code")) else None,
                            description=row.get("description") if not pd.isna(row.get("description")) else None,
                            status=str(row.get("status", "true")).lower() == "true"
                        )
                        db.add(category)
                        success_count += 1
                    else:
                        errors.append(f"ç¬¬{index+2}è¡Œ: ç±»åˆ« '{row['name']}' å·²å­˜åœ¨")
                        error_count += 1

                elif table_name == "ports":
                    # æŸ¥æ‰¾å›½å®¶
                    country_name = str(row["country_name"]).strip()
                    country = db.query(Country).filter(Country.name == country_name).first()
                    if not country:
                        all_countries = db.query(Country.name).all()
                        available_countries = [c[0] for c in all_countries]
                        errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}")
                        error_count += 1
                        continue

                    # æ£€æŸ¥æ¸¯å£æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(Port).filter(Port.name == row["name"]).first()
                    if existing:
                        errors.append(f"ç¬¬{index+2}è¡Œ: æ¸¯å£ '{row['name']}' å·²å­˜åœ¨")
                        error_count += 1
                        continue

                    # å¤„ç†codeå­—æ®µ - æ£€æŸ¥å”¯ä¸€æ€§
                    port_code = row.get("code")
                    if port_code and str(port_code).strip():
                        port_code = str(port_code).strip()
                        # æ£€æŸ¥codeæ˜¯å¦å·²å­˜åœ¨
                        existing_code = db.query(Port).filter(Port.code == port_code).first()
                        if existing_code:
                            errors.append(f"ç¬¬{index+2}è¡Œ: æ¸¯å£ä»£ç  '{port_code}' å·²å­˜åœ¨")
                            error_count += 1
                            continue
                    else:
                        port_code = None  # ç¡®ä¿ç©ºå€¼ä¸ºNone

                    port = Port(
                        name=row["name"],
                        code=port_code,
                        country_id=country.id,
                        location=row.get("location"),
                        status=str(row.get("status", "true")).lower() == "true"
                    )
                    db.add(port)
                    success_count += 1

                elif table_name == "companies":
                    # æŸ¥æ‰¾å›½å®¶
                    country_name = str(row["country_name"]).strip()
                    country = db.query(Country).filter(Country.name == country_name).first()
                    if not country:
                        all_countries = db.query(Country.name).all()
                        available_countries = [c[0] for c in all_countries]
                        errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}")
                        error_count += 1
                        continue

                    # æ£€æŸ¥å…¬å¸æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(Company).filter(Company.name == row["name"]).first()
                    if existing:
                        errors.append(f"ç¬¬{index+2}è¡Œ: å…¬å¸ '{row['name']}' å·²å­˜åœ¨")
                        error_count += 1
                        continue

                    # å®‰å…¨å¤„ç†æ‰€æœ‰å­—ç¬¦ä¸²å­—æ®µ
                    def safe_string_field(value):
                        if value is None or pd.isna(value):
                            return None
                        return str(value).strip() if str(value).strip() else None

                    contact_value = safe_string_field(row.get("contact"))
                    email_value = safe_string_field(row.get("email"))
                    phone_value = safe_string_field(row.get("phone"))

                    company = Company(
                        name=row["name"],
                        country_id=country.id,
                        contact=contact_value,
                        email=email_value,
                        phone=phone_value,
                        status=str(row.get("status", "true")).lower() == "true"
                    )
                    db.add(company)
                    success_count += 1

                elif table_name == "suppliers":
                    # æŸ¥æ‰¾å›½å®¶
                    country_name = str(row["country_name"]).strip()  # å»é™¤ç©ºæ ¼
                    country = db.query(Country).filter(Country.name == country_name).first()
                    if not country:
                        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ‰€æœ‰å¯ç”¨çš„å›½å®¶
                        all_countries = db.query(Country.name).all()
                        available_countries = [c[0] for c in all_countries]
                        errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶ '{country_name}' ä¸å­˜åœ¨ã€‚å¯ç”¨å›½å®¶: {available_countries}")
                        error_count += 1
                        continue

                    # æ£€æŸ¥ä¾›åº”å•†æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(Supplier).filter(Supplier.name == row["name"]).first()
                    if not existing:
                        # ç¡®ä¿phoneå­—æ®µè¢«æ­£ç¡®å¤„ç†ä¸ºå­—ç¬¦ä¸²
                        phone_value = row.get("phone")
                        if phone_value is not None and not pd.isna(phone_value):
                            phone_value = str(phone_value)
                        else:
                            phone_value = None

                        supplier = Supplier(
                            name=row["name"],
                            country_id=country.id,
                            contact=row.get("contact"),
                            email=row.get("email"),
                            phone=phone_value,
                            status=str(row.get("status", "true")).lower() == "true"
                        )
                        db.add(supplier)
                        success_count += 1
                    else:
                        errors.append(f"ç¬¬{index+2}è¡Œ: ä¾›åº”å•† '{row['name']}' å·²å­˜åœ¨")
                        error_count += 1

                elif table_name == "ships":
                    # æŸ¥æ‰¾å…¬å¸
                    company = db.query(Company).filter(Company.name == row["company_name"]).first()
                    if not company:
                        errors.append(f"ç¬¬{index+2}è¡Œ: å…¬å¸ '{row['company_name']}' ä¸å­˜åœ¨")
                        error_count += 1
                        continue

                    # æ£€æŸ¥èˆ¹èˆ¶æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(Ship).filter(Ship.name == row["name"]).first()
                    if not existing:
                        ship = Ship(
                            name=row["name"],
                            company_id=company.id,
                            ship_type=row.get("ship_type"),
                            capacity=int(row["capacity"]) if row.get("capacity") else None,
                            status=str(row.get("status", "true")).lower() == "true"
                        )
                        db.add(ship)
                        success_count += 1
                    else:
                        errors.append(f"ç¬¬{index+2}è¡Œ: èˆ¹èˆ¶ '{row['name']}' å·²å­˜åœ¨")
                        error_count += 1

                elif table_name == "products":
                    # æ£€æŸ¥å¿…å¡«å­—æ®µï¼šäº§å“è‹±æ–‡åç§°
                    if pd.isna(row.get("product_name_en")) or str(row.get("product_name_en", "")).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: product_name_en (äº§å“è‹±æ–‡åç§°) ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    # æ£€æŸ¥å¿…å¡«å­—æ®µï¼šèµ·å§‹æ—¥æœŸ
                    if pd.isna(row.get("effective_from")) or str(row.get("effective_from", "")).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: effective_from (èµ·å§‹æ—¥æœŸ) ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    # æ£€æŸ¥å¿…å¡«å­—æ®µï¼šå›½å®¶åç§°
                    if pd.isna(row.get("country_name")) or str(row.get("country_name", "")).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: country_name (å›½å®¶åç§°) ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    # æ£€æŸ¥å¿…å¡«å­—æ®µï¼šç±»åˆ«åç§°
                    if pd.isna(row.get("category_name")) or str(row.get("category_name", "")).strip() == "":
                        errors.append(f"ç¬¬{index+2}è¡Œ: category_name (ç±»åˆ«åç§°) ä¸èƒ½ä¸ºç©º")
                        error_count += 1
                        continue

                    # æŸ¥æ‰¾å›½å®¶
                    country = db.query(Country).filter(Country.name == row["country_name"]).first()
                    if not country:
                        errors.append(f"ç¬¬{index+2}è¡Œ: å›½å®¶ '{row['country_name']}' ä¸å­˜åœ¨")
                        error_count += 1
                        continue

                    # æŸ¥æ‰¾ç±»åˆ«
                    category = db.query(Category).filter(Category.name == row["category_name"]).first()
                    if not category:
                        errors.append(f"ç¬¬{index+2}è¡Œ: ç±»åˆ« '{row['category_name']}' ä¸å­˜åœ¨")
                        error_count += 1
                        continue

                    # æŸ¥æ‰¾ä¾›åº”å•†ï¼ˆå¯é€‰ï¼‰
                    supplier_id = None
                    if row.get("supplier_name") and not pd.isna(row["supplier_name"]):
                        supplier = db.query(Supplier).filter(Supplier.name == row["supplier_name"]).first()
                        if supplier:
                            supplier_id = supplier.id
                        else:
                            errors.append(f"ç¬¬{index+2}è¡Œ: ä¾›åº”å•† '{row['supplier_name']}' ä¸å­˜åœ¨")
                            error_count += 1
                            continue

                    # æŸ¥æ‰¾æ¸¯å£ï¼ˆå¯é€‰ï¼‰
                    port_id = None
                    if row.get("port_name") and not pd.isna(row["port_name"]):
                        port = db.query(Port).filter(Port.name == row["port_name"]).first()
                        if port:
                            port_id = port.id
                        else:
                            errors.append(f"ç¬¬{index+2}è¡Œ: æ¸¯å£ '{row['port_name']}' ä¸å­˜åœ¨")
                            error_count += 1
                            continue

                    # æ£€æŸ¥äº§å“æ˜¯å¦å·²å­˜åœ¨
                    existing = db.query(Product).filter(Product.product_name_en == row["product_name_en"]).first()
                    if not existing:
                        # å¤„ç†å­—ç¬¦ä¸²å­—æ®µï¼Œç¡®ä¿ç±»å‹æ­£ç¡®
                        code_value = row.get("code")
                        if code_value is not None and not pd.isna(code_value):
                            code_value = str(code_value)
                        else:
                            code_value = None

                        unit_value = row.get("unit")
                        if unit_value is not None and not pd.isna(unit_value):
                            unit_value = str(unit_value)
                        else:
                            unit_value = None

                        currency_value = row.get("currency")
                        if currency_value is not None and not pd.isna(currency_value):
                            currency_value = str(currency_value)
                        else:
                            currency_value = None

                        unit_size_value = row.get("unit_size")
                        if unit_size_value is not None and not pd.isna(unit_size_value):
                            unit_size_value = str(unit_size_value)
                        else:
                            unit_size_value = None

                        brand_value = row.get("brand")
                        if brand_value is not None and not pd.isna(brand_value):
                            brand_value = str(brand_value)
                        else:
                            brand_value = None

                        country_of_origin_value = row.get("country_of_origin")
                        if country_of_origin_value is not None and not pd.isna(country_of_origin_value):
                            country_of_origin_value = str(country_of_origin_value)
                        else:
                            country_of_origin_value = None

                        # å¤„ç†å­—æ®µ
                        pack_size_value = row.get("pack_size")
                        if pack_size_value is not None and not pd.isna(pack_size_value):
                            # pack_size ç°åœ¨æ”¯æŒå­—ç¬¦ä¸²æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²å€¼
                            pack_size_value = str(pack_size_value).strip()
                        else:
                            pack_size_value = None

                        # å¤„ç†ä»·æ ¼å­—æ®µ
                        price_value = None
                        if row.get("price") and not pd.isna(row["price"]):
                            try:
                                price_value = float(row["price"])
                                if price_value < 0:
                                    errors.append(f"ç¬¬{index+2}è¡Œ: price (ä»·æ ¼) ä¸èƒ½ä¸ºè´Ÿæ•°")
                                    error_count += 1
                                    continue
                            except (ValueError, TypeError):
                                errors.append(f"ç¬¬{index+2}è¡Œ: price (ä»·æ ¼) æ ¼å¼é”™è¯¯ï¼Œå¿…é¡»ä¸ºæ•°å­—")
                                error_count += 1
                                continue

                        # å¤„ç†æ—¥æœŸå­—æ®µ
                        from datetime import datetime, timedelta
                        import pandas as pd

                        # å¤„ç†èµ·å§‹æ—¥æœŸï¼ˆå¿…å¡«ï¼‰
                        effective_from_value = None
                        try:
                            if row.get("effective_from") and not pd.isna(row["effective_from"]):
                                if isinstance(row["effective_from"], str):
                                    # å°è¯•è§£æå­—ç¬¦ä¸²æ—¥æœŸ
                                    effective_from_value = pd.to_datetime(row["effective_from"]).to_pydatetime()
                                else:
                                    # å·²ç»æ˜¯datetimeå¯¹è±¡
                                    effective_from_value = pd.to_datetime(row["effective_from"]).to_pydatetime()
                        except Exception as e:
                            errors.append(f"ç¬¬{index+2}è¡Œ: èµ·å§‹æ—¥æœŸæ ¼å¼é”™è¯¯ - {str(e)}")
                            error_count += 1
                            continue

                        # å¤„ç†ç»“æŸæ—¥æœŸï¼ˆå¯é€‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™è‡ªåŠ¨è®¾ç½®ä¸ºèµ·å§‹æ—¥æœŸ+3ä¸ªæœˆï¼‰
                        effective_to_value = None
                        if row.get("effective_to") and not pd.isna(row["effective_to"]):
                            try:
                                if isinstance(row["effective_to"], str):
                                    effective_to_value = pd.to_datetime(row["effective_to"]).to_pydatetime()
                                else:
                                    effective_to_value = pd.to_datetime(row["effective_to"]).to_pydatetime()
                            except Exception as e:
                                errors.append(f"ç¬¬{index+2}è¡Œ: ç»“æŸæ—¥æœŸæ ¼å¼é”™è¯¯ - {str(e)}")
                                error_count += 1
                                continue
                        else:
                            # å¦‚æœæ²¡æœ‰ç»“æŸæ—¥æœŸï¼Œè‡ªåŠ¨è®¾ç½®ä¸ºèµ·å§‹æ—¥æœŸ+3ä¸ªæœˆ
                            if effective_from_value:
                                effective_to_value = effective_from_value + timedelta(days=90)  # çº¦3ä¸ªæœˆ

                        # éªŒè¯æ—¥æœŸèŒƒå›´
                        if effective_from_value and effective_to_value:
                            if effective_to_value < effective_from_value:
                                errors.append(f"ç¬¬{index+2}è¡Œ: ç»“æŸæ—¥æœŸä¸èƒ½æ—©äºèµ·å§‹æ—¥æœŸ")
                                error_count += 1
                                continue

                        product = Product(
                            product_name_en=row["product_name_en"],
                            product_name_jp=row.get("product_name_jp"),
                            code=code_value,
                            country_id=country.id,
                            category_id=category.id,
                            supplier_id=supplier_id,
                            port_id=port_id,
                            unit=unit_value,
                            price=price_value,
                            currency=currency_value,
                            unit_size=unit_size_value,
                            pack_size=pack_size_value,
                            brand=brand_value,
                            country_of_origin=country_of_origin_value,
                            effective_from=effective_from_value,
                            effective_to=effective_to_value,
                            status=str(row.get("status", "true")).lower() == "true"
                        )
                        db.add(product)
                        success_count += 1
                    else:
                        errors.append(f"ç¬¬{index+2}è¡Œ: äº§å“ '{row['product_name_en']}' å·²å­˜åœ¨")
                        error_count += 1

                else:
                    errors.append(f"ç¬¬{index+2}è¡Œ: ä¸æ”¯æŒçš„è¡¨ç±»å‹ '{table_name}'")
                    error_count += 1
                
            except Exception as e:
                error_count += 1
                errors.append(f"ç¬¬{index+2}è¡Œ: {str(e)}")
        
        # æäº¤äº‹åŠ¡
        if success_count > 0:
            db.commit()
        
        return {
            "success_count": success_count,
            "error_count": error_count,
            "skipped_count": skipped_count,
            "errors": errors,
            "skipped_items": skipped_items
        }
        
    except Exception as e:
        db.rollback()
        raise e
